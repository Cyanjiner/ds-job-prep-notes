[["index.html", "Data Science Prep Notes Chapter 1 Summary resources for DS learning 1.1 Statistics, Probability, and A/B Testing 1.2 SQL / R / Python / Visualization Tools 1.3 Machine Learning resources 1.4 Interview Questions &amp; Resume", " Data Science Prep Notes Jiner Zheng 2022-09-29 Chapter 1 Summary resources for DS learning 1.1 Statistics, Probability, and A/B Testing 1.1.1 Stanford Courses (NON-EDUC): STATS 160-Introduction to Statistical Methods COVERS estimation | confidence intervals | test of hypotheses | t-tests | correlation &amp;&amp; regression | analysis of variance and chi-square tests STATS 116-Theory of Probability or CS109-Introduction to Probability for Computer Scientists COVERS probability spaces | discrete spaces (binomial, hypergeometric, Possion) | continuous spaces (normal, exponential) and densities | random variables | expectation | independence | conditional probability | the laws of large numbers and central limit theorem (CLT) 1.1.2 Online Resources Coursera: Introduction to Probability and Data with R by Duke University: If you are already familiar with R then skip week 3-5 sections, week 6 &amp; 8 are most useful for reviewing important probability concepts) Coursera: Six Sigma Advanced Define and Measure Phases: Week 3-5 covers probability &amp; statistics and statistical distribution Book: Practical Statistics for Data Scientists (available on Oreilly Stanford account has free access) Useful website for reviewing / practicing prob &amp; stats questions: Brilliant Udacity: Introduction to A/B Testing by Google Additional Tips: A/B Testing is NOT required by all DS/DA jobs, but if you are interested in applying for a Product Data Scientist then it is REQUIRED. Be sure to browse DS/DA interns JD so that you know what skills would be needed. 1.2 SQL / R / Python / Visualization Tools SQL syntax guide: SQL ZOO, W3schools SQL classes: Stanford class: CS145 Database Management and Data Systems Udemy: SQL-MySQL for Data Analytics and Business Intelligence + The Ultimate MySQL Bootcamp (should take less than a week to learn these two courses) Other resources: 18 BEST SQL online learning resources SQL Practices: Hackerrank (easy), Summary of SQL in LeetCode (go for medium and hard!!) MySQL instructions on Windows function &amp; Frame Clause, WITH common table expression (very useful) Udemy Python courses: Data Analysis with Pandas and Python + Python for Data Science and Machine Learning Bootcamp (tip: if you are familiar with Python then I recommend directly taking Andrew Ng’s ML courses and practice ur python ds coding thru hands-on projects and also regularly checking the Complete python data science cheatsheets) R: Datacamp (for learning how to program in R. However, most tech companies prefer Python so no need to be an R expert, but it is good to learn especially if you are also interested in doing research in academic) Tableau / Power BI: Learning Path: Your Guide to become a Tableau Expert | Tableau Tutorial | Power BI Tutorial (looking at online tutorial guides are sufficient for learning data viz tools cuz they are easy, but if you prefer taking online video lessons then Coursera—Data Visualization and Communication with Tableau by Duke will be a good choice). Other helpful resources: The R Gallery (website that contains useful R visualizations examples and code) R Markdown Guide (should be helpful to learn Rmd too cuz it makes everything look pretty) Collection of RStudio Cheatsheets (a collection of cheat sheets for all common used data manipulation and visualization packages (e.g. ggplot2, dplyr, tidyr, stringr, lubridate, shiny, etc.) R Statistical Modeling Code Syntax Guide Python Data Science Cheat Sheet (Beginner) Python Data Science Cheat Sheet (PDF) (Collection of popular python libraries cheat sheets including Numpy, Pandas, Seaborn, Matplotlib, Scikit, SciPy - linear algrebra) Real Python Tutorials 1.3 Machine Learning resources 1.3.1 Stanford Classes: STATS 202-Data Mining and Analysis (Terms: Aut, Sum) –&gt; course website STATS 216-Introduction to Statistical Learning (Terms: Win) –&gt; course syllabus: This is a math-light version of STATS 202 CS 129-Applied Machine Learning (Terms: Win) –&gt; course website: similar to the ML course by Andrew Ng on Coursera CS 229-Machine Learning (Terms: Aut, Win, Spr, Sum) –&gt; course website: This is a very MATHY ML class, so if you are not comfortable with doing mathematical proofs of some ML theories do not take it for credit. USEFUL RESOURCE: A collection/guide of Stanford AI courses under CS/STATS department | Stanford Grades Distribution 2020 1.3.2 Online Resources Machine Learning Specialization by Andrew Ng on Coursera Topics covered: Supervised Learning: multiple linear regression, logistic regression, neural networks, &amp; decision trees) Unsupervised Learning: clustering, dimensionality reduction, recommender systems Some AI &amp; ML innovation: evaluating and tuning models, taking a data-centric approach to improving performance Applied Learning Project: Build ML models using Numpy &amp; Scikit Build &amp; train a neural network with Tensorflow to perform multi-class classificaton Build &amp; use decision trees and tree ensemble methods, including forest and boosted trees Build recommender systems with a collaborative filtering approach and a content-based deep learning method 15 hours of expert ML videos. 《An Introduction to Statistical Learning》(This book is also used for Stanford’s course STATS 202: Data Mining and Analysis) Machine Learning 101 on Towards Data Science and many other articles Other useful resources (notes): Data Science Specialization Course Notes (Notes for all 9 courses in Coursera Data Science Specialization from JHU, taken by Xing —&gt; topics include Experimental Design / EDA / Statistical Inferences / Regression models / Practical Machine Learning, etc.) Notes on《Hands-on-Machine-Learning-with-Scikit-Learn-Keras-and-TensorFlow》 (GitHub repo for notes &amp; code [.ipynb] on the book w/ same name) This book is also available on Oreilly Data Science with R: A Resource Compendium very very very complete collection of data science resources with R by Martin Monkman, ranging from topics like data wrangling, Bayesian methods, to time series modeling &amp; ML methods) Natural Language Processing Notes – Python (chapters from Python Notes for Linguistics by Alvin Chen). Additional Tips: All resources listed as other useful resources are mainly for your references when you need to actually implement certain methods / conduct a project / or to review certain syntax or concept. I personally DO NOT recommend beginners to start their learning journey with these resources, because it is much more important that you have already built a SOLID foundation in all fields mentioned above through SYSTEMATIC learning processes. 1.4 Interview Questions &amp; Resume MIT Sample Resumes VMock Dashboard (A smart platform that rates &amp; analyzes your resume) FAANGPath Resume Template (a FREE tech resume template built with LaTeX on Overleaf) DS Interview related GitHub respository: Data-Science-Interview-Resources | 120-Data-Science-Interview-Questions Cracking-the-data-science-interview(this one contains almost ALL related resources for DS job prepraration, but it might be overwhelming if you just start your DS-prep journey [a lot of cheat sheets on KEY topics/concepts, so I recommend selectively using some resources there). "],["statistics-and-probability.html", "Chapter 2 Statistics and Probability 2.1 IMPORTANT Concepts to review 2.2 Designing Studies", " Chapter 2 Statistics and Probability 2.1 IMPORTANT Concepts to review Probability Basics and Random Variables beginnings of prob: sample spaces, basic counting and combinatorial principles (not necessary to know all ins-and-outs but helpful to understand basics for simplifying problems random variables expectation variance covariance Probability Distributions discrete &amp; continuous uniform, normal, poisson, binomial, geometric Hypothesis Testing central limit theorem sampling distributions p-values confidence intervals type I and type II errors Modeling maximum likelihood estimation bayesian statistics 2.1.1 Key terms for Variability Metrics Variability (also dispersion) measures whether the data values are tightly clustered or spread out. Deviations / Errors / Residuals: the difference between the observed values and the estimate of location (i.e. mean / median, etc.) Variance / mean-squared-error: the sum of squared residuals from the mean divided by n-1 where n is the number of data values. Standard deviation: the square root of variance Mean absolute deviation: the mean of the absolute values of the deviations from the mean. Percentile / Quantile: the value such that P percent of the values take on this value or less and (100-P) percent take on this value or more. Interquartile range / IQR: the difference between the 75th percentile and the 25th percentile. 2.2 Designing Studies Population: A collection of individuals or objects that we will be analyzing on their properties. Sample: A representative subset of population chosen to be analyzed (a well-chosen sample contains most of the information about a particular population parameter. 2.2.1 Identifying variables type: Numerical vs. Categorical numerical —&gt; continuous or discrete? (based on whether or not they can take on an infinite number of values or only non-negative whole numbers, respectively) categorical —&gt; ordinal? (whether or not levels have a natural ordering) Associated (Explanatory) vs. Independent (Response) —&gt; show relationships w/ other vars? Confounding variables 2.2.2 Classify study type as ovbservational or experimental Observational studies: researcher collects data by observing but not directly interfering with how data arise —&gt; correlation only Retrospective study: when an observational study uses data from the past Prospective study: …. data are collected throughout the study Experiments: when researchers randomly assign subjects to treatments (can be causal) 2.2.3 Sampling Techniques Probability Sampling Random sampling: choosing sample randomly without any given logic —&gt; each member has an equal chance of being selected in the sample. Stratified sampling: First divide population into homogenous strata (subjects within each stratum are similar but different across strata), then randomly sample from within each strata. e.g. to make sure both genders are equally represented in a study, we might divide the population into males and females and then randomly sample from within each gender group Cluster sampling: Divide population into heterogenous clusters (subjects within clusters are different but clusters are similar to each other —&gt; randomly sample a few clusters Multistage sampling add one other step to cluster sampling: randomly sample observations from WITHIN each cluster Systematic sampling Non-Probability Sampling Snowball Quota Judgement Convenience sample bias occurs when individuals who are easily accessible, are more likely to be included in the sample. Non-response bias happens when only a non-random proportion of the randomly sampled people respond to a survey —&gt; sample no longer representative (initial sample is random but the final valid sample is not) e.g. when we take a random sample of individuals from Stanford, but certain groups of population, such as from a lower socioeconomic status, are much less likely to respond to the survey —&gt; our sample is not representative enough of the entire Stanford community Volunteer Response bias occurs when sample consists of only people who volunteer to respond bcuz they have strong opinions on the issue (no initial random sample) 2.2.4 Principles of Experimental Design—Control, Randomize, Replicate, and Block—and their purposes Control — compare treatment of interest to a control group Randomize — randomly assign subjects to treatments Replicate — collect a sufficiently large sample, or replicate the entire study Block — block for variables known or suspected to affect outcome if there are variables known or suspected to affect the response variable, first group the subject into blocks based on these variables —&gt; then randomized cases within each block to treatment groups e.g. design an experiment to investigate if energy gels make you run faster: the treatment group gets the energy gel, the control group does not. It is suspected that energy gels might effect pro and amateur athletes differently therefore we block for pro status. &lt;-- we divide our sample into pro and amateur athletes, then randomly assign pro and amateur athletes to treatment and control groups so that both pro and amateur athletes are equally represented in the resulting treatment and control group. Blocking variable vs. Explanatory variable Explanatory variables (factors) are conditions we impose on our experimental units. Blocking variables are characteristics that the experimental units come with (which may affect how experimental units respond to response variable differently). Other terminologies Placebo: a fake treatment, often used as the control group in medical studies Placebo effect: when experimental units show improvement just becuz they believe they’re receiving a special treatment Blinding: when experimental units DO NOT know they are in the control or treatment groups. Double-blind study: when BOTH the experimenters and researchers DO NOT know who is in the control or treatment group. Experimental Design Workflow: Control any possible confounders / confounding variables (non-explanatory factors that may influence different responses) Randomize into treatment and control groups Replicate by using a sufficiently large sample or repeating the experiment Block any variables that might influence the response * Stratified sampling allows for controlling for possible confounders in the sampling stage, while blocking allows for controlling for such variables during random assignment. 2.2.5 Random Sampling vs. Random Assignment If random sampling has been employed in data collection, the results should be generalizable to the target population. (but still NOT causal) WHY? —&gt; if subjects are randomly selected from the population, then each subject in the population is equally likely to be selected so that the resulting sample is likely representative of the population. If random assignment has been employed in study design, the results suggest causality. WHY? —&gt; in our sample, subjects usually exhibit slightly different characteristics from one another. Through random assignment, we ensure that these different characteristics are represented equally in the treatment and control groups —&gt; allows us to attribute any observed difference between treatment and control groups to treatment being observed on the subjects, since otherwise these groups are essentially THE SAME. A study that relies on volunteers employ random assignment (experiment), but NOT random sampling can be used to make causal conclusions but ONLY apply to the sample (so results cannot be generalized). A study that uses NO random assignment, but DOES use random sampling, is a typical observation study. Results can ONLY be used to make correlation statements, but they CAN be generalized to the population at large. A study that DOES NOT use random assignment or random sampling, can ONLY be used to make correlational statements, and these conclusions are NOT generalizable. This is an unideal observational study. 2.2.6 Hypothesis Tests and Resampling 2.2.7 Statistical Significance and p-values p-value: Given a chance model that embodies the null hypothesis, the p-value is the probability of obtaining results as unsusual or extreme as the observed results. Alpha: The probability threshold of \"unusualness\" that chance results must surpass for actual outcomes to be deemed statistically significant. Type 1 error (false-positive): Mistakenly concluding an effect is real (when it is due to chance). (i.e. reject H0 when it is actually true) Type 2 error (false-negative): Mistakenly concluding an effect is due to chance (when it is real). (i.e. fails to reject H0 when it is actually false) "],["ab-testing.html", "Chapter 3 A/B Testing 3.1 What is A/B testing? 3.2 What you can’t do with A/B testing? 3.3 Defining the hypothesis 3.4 Defining Metrics and Gathering Data 3.5 Designing an A/B test 3.6 Step1: Choose and characterize metrics for both sanity check and evaluation 3.7 Step 2: Choose significance level, statistical power and practical significance level 3.8 Step 3: Calculate required sample size 3.9 Step 4: Take sample for control/treatment groups and run the test 3.10 Step 5: Analyze the results and draw conclusions 3.11 Other things to keep in mind", " Chapter 3 A/B Testing Experimentation ranging from the underlying infrastructure, to design metrics and dashboards, to running and analyzing experiments to the processing culture needed to facilitate data-driven solutions 3.1 What is A/B testing? A/B testing is a general methodology used online when you wanna test out a new product or a feature. And what you’re doing is you are going to take two sets of users and you will show one set, a control set, your existing product or feature, and then another set, your experiment, the new version. Then, you will examine how did these users from two groups respond differently in order to determine which version of your feature is better. Example: It can be a novel big change or addition in product or feature like when Amazon initially decided to launch their first personalized product recommendations feature based on A/B testing results that showed a huge increase in revenue by adding this new feature. It can also be a very small or trivial feature such as when Google tested 41 different shades of blue. The key thing in A/B testing is that you have a consistent response from your control and experiment group so that you can actually determine and structure the experiment to determine whether there is a significant behavior change in your experiment group. The goal in A/B testing is to design an experiment that is gonna be robust and give you repeatable results so that you can actually make a good decision about whether or not to actually launch that product or feature. A/B Testing compared to hypothesis testing in traditional fields of study: In traditional fields of study such as clinical trials in psychology or medical research, we know a lot of information about participants such as their demographics, and we usually have a relatively small number of participants. However, when testing an online product, we might have millions of users, hundreds or thousands of clicks, etc., and we DO NOT know much about who is taking those actions on the other end. 3.2 What you can’t do with A/B testing? Case 1: New Experiences (e.g. premium service that offers additional functionality) (p.s. to access premium, user need to upgrade, create a log-in, and explore new functionality) A/B testing isn’t useful when you wanna test out new experiences. Because when you are testing a new experience, you have an existing set of users and they might feel that you have changed their experience and they preferred their old way (and this is change aversion). The other case is that they can be really like this new experience and they test out everything (this is called a novelty effect). What happens in a new experience are two issues: we are not sure about the baseline for comparison we can’t control the exact time we need in order to actually have our users adapt to the new experience. So that we can’t know the plateaued experience so that we can actually make a robust decision. Case 2: Time-dependent/related cases (e.g. Referral) For example, if we have a website that recommends apartment rentals, but people don’t look for apartments that often, what you really want is to grow your business by referrals to other people who like your service. The main issues in this case are: The scope of an experiment will be really hard to measure whether people actually come back to you from more referrals or from other reasons. We can’t estimate the time that people actually spend in making the action of referral happen. Cases 3: Missing/Complete content or services A/B testing can’t really tell us if we are missing something. For example, if we are building a song or a book reviews website, A/B testing can’t tell us if we are missing the entire other book that we should be reviewing but we aren’t reviewing at all. Other Techniques to complement A/B testing: Qualitative research: A/B testing can give you a lot of broad quantitative data, but other techniques give you very deep and qualitative data that are really complimentary to A/B testing User experience research Focus groups and surveys Human evaluations Quantitative approach: We can also analyze the logs of what users did on the website to see if a hypothesis can be developed about what’s causing changes in their behavior. And that’s something where you may want to go forward and actually design and randomize an experiment through a perspective analysis. We can use the two data sources to compliment each other. 3.3 Defining the hypothesis Initial Hypothesis: changing the “start now” button from orange to pink will increase how many students explore Audacity’s courses. Choosing Metrics: BAD CHOICES: Total # of courses completed —&gt; time issue (not should about the actual duration to complete course) # of clicks —&gt; percentage issue (e.g. 2/12 clicks in control group vs. 1/3 clicks in experiment group: # of clicks in experiment is \\(\\downarrow\\), but its ratio is actually \\(\\uparrow\\) GOOD CHOICES: \\[\\begin{equation} \\text{CTR (click-through-rate)} = \\frac{\\text{Number of clicks}}{\\text{Number of Page views}} \\end{equation}\\] \\[\\begin{equation} \\text{Click-through probability)} = \\frac{\\text{Unique visitors who click}}{\\text{Unique visitors to page}} \\end{equation}\\] Updated hypothesis: Changing the “Start Now” button from orange to pink will increase the click-through-probability of the button. (--&gt; assume that this will ultimately increase business profits). 3.4 Defining Metrics and Gathering Data 3.4.1 High-Level concepts for metrics define business objectives break overall objectives down to step by step using customer funnel Funnel –&gt; we typically have fewer and fewer users that get to each stage of the funnel OEC (overall evaluation criterion) —&gt; a composite metric / an objective weighted function that combines all of these different metrics Categories of SUMMARY Metrics sums and counts means, medians, percentiles probability (0 or 1) and rate (0 or more) ratios 3.4.2 Methods for Coming up w/ Proxy Metrics or Validating Metrics Retrospective Analysis: if we have logs or other data capture mechanisms to see what users do. Running analyses on this existing set of observational data without an experiment structure is called retrospective analysis or observational analysis. [correlation NOT causation] Long-term Prospective Experiments Human Evaluation 1. It is important to take into account your corporate culture as you define business metrics becuz some companies care more about obtaining market share / making revenues, but others just wanna make their existing users happy 2. It is usually more robust to triangulate between different methods. For example, if we wanted to see if students are really happy with our course website, we might look through our logs and say that somebody took a second course, which we’ll say is being happy: 1) what did they do? 2) how long did they spend? 3) how many months were they active for this site? —&gt; we wanna get some baseline for that. And then given that they took a second course, then we might also want to trigger surveys that happened within your site or do a focus group where people who’ve done a single course actually get a survey that says are you considering taking a second course? 3.4.3 Gathering Additional Data External data: see what data is OUT relating to similar websites / mobile applications User Experience Research (UER): tracks a specific user experience and understand a typical user journey in terms of experience good for brainstorming ideas from coming up with ideas to changes to test / to identifying problems with your user experience in a way that you can translate into a possible metric that you could use to evaluate your A/B test. can use special equipment such as an eye-tracking cameras to see what users are looking at even if they don’t click on the button want to validate results of UER with something like the retrospective analyses Focus Groups: where you bring a bunch of users or potential users together for a group discussion to elicit feedback. You can talk to more total users than with a UER study. but you can’t go as deep for each person. get feedback on hypotheticals run the risk of group think and convergence on fewer opinions Surveys: where u recruit a bunch of people to ask them questions, either online, or in person, or via telephone cheap for getting almost all users involved data often quantitative but not very deep or individually customized useful for metrics you cannot directly measure need to be careful about survey results —&gt; bcuz users don’t have to tell the truth and their answers can be dependent on how the questions are phrased. Example: Which techniques to use? Measure user engagement (course completion too long-term) Survey | UER + Retrospective analysis (of users who have completed courses and see what behaviors they have in common) Decide whether to extend inventory Focus group —&gt;get ideas from users about what products they wanna see External data —&gt; what users buy from other shopping sites Which ads get most views External data —&gt; look for studies to see if there’s something we can measure like time spent on the page / mouse hover events —&gt; use as a proxy for whether the ad was viewed UER —&gt; to observe users and see what ads they are paying attention to with an eye-tracking camera and then try to find a metric that correlates with that 3.4.4 Segmenting and Filtering Data External reasons: We want to filter out abuse on our site such as spam or fraud (e.g. competitor visiting) Internal reasons: when our change only impacts a subset of the traffic GOAL: to de-bias or dull-bias our data 3.5 Designing an A/B test reference: 1. A Summary of Udacity A/B Testing Course by Kelly Peng The A’s and B’s of A/B Testing by Tanmayee W 3.5.1 Summary workflow of A/B testing: Choose and characterize metrics to evaluate experiments —&gt; identify what we care about and how we wanna measure the effect Choose significance level (alpha), statistical power (1-beta) and practical significance level —&gt; we rly wanna launch the change if tests are statistically significant Calculate required sample size Take sample for control or treatment groups and run the test Analyze results and draw valid conclusions 3.6 Step1: Choose and characterize metrics for both sanity check and evaluation Invariant metrics: metrics we choose for sanity check these metrics should NOT change across control and experiment groups during the course of the experiment they are NOT supposed to be affected by the experiment if they DO change then there is something fundamentally wrong in the experiment setup. Evaluation metrics: metrics used to measure which variation is better e.g. we could use daily active users (DAU) to measure user engagement e.g. use click through rate (CLR) to measure a button design on a webpage Four Categories of Metrics to keep in mind Sums &amp; counts Distributional metrics (mean | median | percentiles) Probability &amp; rates (e.g. click-through probability, CLR) Ratios: any two numbers divide by each other (e.g. # of revenue-generating clicks / total # of clicks) Sensitivity and Robustness to consider we want to choose a metric that has high sensitivity —&gt; metric can pick up the change we care about we want to choose metric to be robust against changes we DO NOT care about —&gt; metric does not change a lot when nothing we’re interested happened Measure Sensitivity &amp; Robustness Run experiments Use A/A test to see if metrics pick up difference (if yes, then metrics are NOT robust) Retrospective analysis 3.7 Step 2: Choose significance level, statistical power and practical significance level Usually the significance level is 0.05 and power is set as 0.8. Practical significance level varies depends on each individual tests —&gt; tells us how much change the test detscts that makes we rly wanna launch the change. It is important to understand what constitutes as statistically significant change may NOT be practically significant change! Business needs have to be identified and ROI (return on investment) has to calculate if the change has to be actually rolled out. Is the roll-out worth the efforts? | Is business impact greater if we decide to launch the change? While we make these critical decisions, it may be worthwhile to consider opportunity costs (the loss of potential gain from other alternatives); engineering and roll-out costs (costs to launch the new product or services); customer support or sales issues that may be involved if we go ahead with the change. 3.8 Step 3: Calculate required sample size In this step, we would need to consider the choice of metric | choice of unit of diversion | choice of population into account bcuz they ALL affect the variability of our metrics. Then decide on the size of experiment. Subject for a/b testing is commonly called Unit of Diversion event-based (e.g. page views) —&gt; useful for measuring latency change such as website load time anonymous id-based (e.g. cookies) —&gt; user visible changes user-id based —&gt; user visible changes Population depends on what subjects are relevant for the study under consideration. Is the population of particular demographic, region/country relevant? Choose accordingly. How to reduce the size of an experiment to get it done faster? increase significance level alpha reduce power (1-beta) which means increase beta change the unit of diversion if originally it is not the same with unit of analysis unit of analysis: denominator of our evaluation metric 3.9 Step 4: Take sample for control/treatment groups and run the test Things to keep in mind: Duration: What’s the best time to run it and how long the experiment would take place? Students going back to college? Holidays? Weekend vs. weekdays? Exposure: What fraction of traffic we want to expose the experiment to? Suggestion is to take a small fraction, run multiple tests at the same time (different days: weekend, weekday, holiday). Learning effect: When there’s a new change, in the beginning users may against the change (change aversion) or use the change a lot (novelty effect) But overtime, user behavior becomes stable and more fit to measure any effects of change, which is called plateau stage . the key thing to measure learning effect is TIME, but in reality we don’t have much luxury of taking that much time to make a decision. Suggestion: run a smaller group of users for a longer period of time 3.10 Step 5: Analyze the results and draw conclusions 3.10.1 First step — Sanity Check Check if our invariant metrics have changed. If sanity check failed then we do not proceed becuz it means there’s something wrong with experiment setup. —&gt; go analyze why sanity check has failed by using retrospective analysis or look into if there exists any learning effect. 3.10.2 Second step — Analyze the Results Case 1: One Single Metric —&gt; if NOT significant First try: break down the experiment into different segments check results on different platforms (web &amp; mobile) check results across different periods of time (days, weeks, months, years, etc.) Second try: cross checking by using different methods e.g. compare with non-parametric sign test (a test that compares the sizes of two groups &amp; it is non-parametric or “distribution free” which means it DOES NOT assume the data comes from a particular distribution) with parametric hypothesis test (tests that make assumptions about parameters of the population distribution which the sample was taken — e.g. Two-sample t-test, paired t-test, ANOVA, Pearson correlation). if two tests NOT agree —&gt; look into data critically cuz we might be suffering from Simpson's paradox (a phenomenon when a trend appears in different groups of data but it disappears when the different groups are combined and looked at holistically) Reasons for Simpson’s paradox: experiment setup is incorrect the change affects the new users and experienced users differently Case 2: Measuring Multiple Metrics at the same time One potential problem is that we might see a significant result by chance e.g. if we are running tests with 20 variants, and we test each hypothesis separately: P (one significant result) = 1 - P (no significant results) P (one significant result) = 1 - (1 - 0.05) ^20 = 0.64 Ways to Solve this problem: Bootstrap: divide the test samples into further more sample and run experiments again and again on each sub-divided sample —&gt; the significant metric should disappear if it occurred by chance in the first place. Bonferroni correction: Divide the significance level 0.05 by the number of tests run. Then check the statistical significance of our tests as against this adjusted level of significance. The problem of Bonferroni correction is it tends to be too conservative. If many metrics are tested at the same time, maybe none of them turned out to be significant. Control Family-wise Error Rate (FWER): Adjust the probability that any metric will show false positives Control false discovery rate (FDR): Fix an acceptable rate of false positives generated by any metric in the experiment. FDR = # false positives / # total rejections Say we decide 0.05 as FDR then this means that out of 100 samples, we are ready to accept 5 false positives per test. Another potential problem if — What if metrics are NOT moving at the SAME direction as we expected? e.g. expect DAU &amp; average length of time users use our app both increase. HOWEVER, we observe DAU decrease while average length of time increase. To solve this problem —&gt; dive deeper and figure out WHY Have one OEC (Overall Evaluation Criterion). A good OEC gives us a balance between short-term and long-term goal, or balance between different metrics. However, we need to keep in mind that OEC helps us understand what our business care about, and how do we balance metrics such as stay time and click, but it DOES NOT help us make a product change decision. 3.10.3 Last step — Draw Conclusions When we DO have a significant result from a test, we need to introspect a few things before deciding launch the change or not: Do we understand the change? What does the change mean to users and business stakeholders? Will the change actually bring about value for the business? How will our users feel post-launch? Will there be differentiated opinions among different customer segments? Do we risk losing some of our customers? In other words: do I have statistically significant and practically significant result in order to justify the change? Do I understand what the change actually done to our user experience? Is it worth it to launch? 3.11 Other things to keep in mind RAMP UP Always do a ramp up when we wanna launch a change after a/b testing. Becuzz we wanna know if there’s any incidental impact to unaffected users that we didn’t test in the original experiment. When we are ramping up the change, we may see the effect flatten out. Thus making the tested effect not repeatable. Reasons including: Seasonality Effect: Social network platform user behavior changes a lot when students start summer vacation or going back to school. Holidays affect users’ shopping behaviors a lot. Solution: use hold-back method —launch the change to everyone except for one small hold-back group of users, and continue comparing their behavior to the control group Novelty effect / Change Aversion: cohort analysis — involves breaking down dataset into related groups (or cohorts) over time and observing how their behavior changes. These groups or cohorts usually share common characteristics or experiences within a defined time-span. RISK: What risk are participants exposed to? The main threshold is whether the risk exceeds that of “minimal risk”. Minimal risk: defined as the probability and magnitude of harm that a participant would encounter in normal daily life. The harm considered encompasses physical, psychological and emotional, social, and economic concerns. If the risk exceeds minimal risk, then informed consent is required. BENEFIT: What’s the potential benefit of the outcome of the study? It is important to be able to state what benefit would be from completing the study. CHOICE: What other choices do participants have? In online experiments, the issues to consider are what the other alternative services that a user might have, and what the switching costs might be, in terms of time. money, information, etc. PRIVACY: What privacy do participants have? For new data being collected and stored, how sensitive is the data and what are the internal safeguards for handling that data? Then, for that data, how will it be used and how will participants’ data be protected? How are participants guaranteed that their data, which was collected for use in the study, will not be used for some other purposes? "],["database-management-and-data-systems-sql.html", "Chapter 4 Database Management and Data Systems (SQL) 4.1 CRUD (create, read, update, delete) Operations 4.2 Exploratory Data Analysis in SQL (T-SQL) 4.3 Advanced SQL - loops/CTE/Windows", " Chapter 4 Database Management and Data Systems (SQL) SQL (Structured Query Language) is used to answer questions / extract information both within and across relational database tables —&gt; high-level / parallel programming language Database schemas show data types for each field (column) in all tables (data frame), and they also show relationships between tables. cardinality of relation —&gt; # of tuples (rows / records) arity of the relation —&gt; # of columns (attributes) relation = table A key is a minimal subset of columns that acts as a unique identifier for tuples in a relation. SQL Style Guide by Simon Holywell Keywords are reserved words for operations. 4.1 CRUD (create, read, update, delete) Operations 4.1.1 CREATE —&gt; Databases | Tables | Views | Users | Permissions | Security Groups /* create a new table w/ column names, data type, size */ CREATE TABLE test_table( -- unique table name test_date date, test_name varchar(20), test_int int, PRIMARY KEY (test_date, test_name) ) /* data types: */ Dates: date (YYYY-MM-DD) | datetime (YYYY-MM-DD hh:mm:ss) | time Numeric: int | decimal | float | bit (1=TRUE, 0=FALSE. Also accepts NULL) Strings: char | varchar | nvarchar /* create a copy of an existing table */ CREATE TABLE new_table_name AS SELECT column1, column2, ... FROM existing_table_name, WEHRE conditions; 4.1.2 INSERT, — insert new records into existing database tables /* insert new columns &amp; values */ INSERT INTO table_name (col1, col2, col3) VALUES (&#39;value1&#39;, &#39;value2&#39;, &#39;value3&#39;) /* insert + select columns &amp; values from another existing table */ INSERT INTO table_name (col1, col2, col3) SELECT column1, column2, column3 FROM other_table WHERE condition(s); 4.1.3 UPDATE — Amend existing database records UPDATE table_name SET column1 = value1, column2 = value2 WHERE condition(s) 4.1.4 DELETE — delete existing records from tables DELETE FROM table_name WHERE condition(s) /* another method: TRUNCATE --&gt; remove all data from ALL columns at once */ TRUNCATE TABLE table_name 4.1.5 Declare Variables —&gt; so it will be easier to use in later conditions without repetitively calling the same values -- declare your variables DECLARE @start DATE DECLARE @stop DATE DECLARE @affected INT; -- set relevant values for each variable SET @start = &#39;2022-01-01&#39; SET @stop = &#39;2022-12-31&#39; SET @affected = 5000; -- threshold for # of affected customers SELECT column1, column2, affected_customers FROM table_name WHERE date BETWEEN @start AND @stop AND affected_customers &gt;= @affected; 4.1.6 Temporary tables SELECT col1, col2, col3 INTO #my_temp_table -- #my_temp_table exists until connection or session ends FROM my_existing_table WHERE condition(s); -- Remove table manually DROP TABLE #my_temp_table 4.1.7 READ | VIEW Example: SFW query —&gt; SELECT FROM WHERE statements Selection is the operation of filtering a relation’s tuples on some condition. Projection is the operation of producing an output table with tuples that have a subset of their prior attributes. SELECT indicates which fields should be selected. FROM indicates where these fields are located. SELECT DISTINCT allows you to select field content. SELECT DISTINCT var_name1 AS new_var_name1, var_name2 FROM table_name WHERE condition(s); DROP DATABASE drops an existing SQL database ALTER DATABASE modifies a database ALTER TABLE modifies a table DROP TABLE table_name deletes a table CREATE INDEX creates an index (search key) DROP INDEX deletes an index BACKUP DATABASE is used in SQL Server to create a full back up of an existing SQL database TO DIST = 'filepath'; Use aliasing to rename columns: View is a virtual table that is the result of a saved SELECT statement. When accessed, views automatically update in response to updates in the underlying data. CREATE VIEW new_table_name AS SELECT id, var_name1, var_name2 FROM table_name; 4.2 Exploratory Data Analysis in SQL (T-SQL) 4.2.1 GROUP BY | HAVING | WHERE GROUP BY splits data up into combinations of one or more values WHERE filters on row values HAVING appears after the GROUP BY clause and filters on groups or aggregates /* List the number of customers in each country, ordered by the country with the most customers first.*/ SELECT COUNT(customerID), country, FROM customers GROUP BY country ORDER BY COUNT(customerID) DESC; /* List the # of customers in each country, sorted high to low (but only include countries with more than 5 customers) */ SELECT COUNT(CustomerID), Country FROM Customers GROUP BY Country HAVING COUNT(CustomerID) &gt; 5 ORDER BY COUNT(CustomerID) DESC; /* List if the employees &quot;Davolio&quot; or &quot;Fuller&quot; have registered more than 25 orders */ SELECT Employees.LastName, COUNT(Orders.OrderID) AS NumberOfOrders FROM Orders INNER JOIN Employees ON Orders.EmployeeID = Employees.EmployeeID WHERE LastName = &#39;Davolio&#39; OR LastName = &#39;Fuller&#39; GROUP BY LastName HAVING COUNT(Orders.OrderID) &gt; 25; 4.2.2 JOIN examples /* INNER JOIN selects records that have matching values in BOTH tables */ SELECT column_name FROM table1 INNER JOIN table2 ON table1.column_name = table2.column_name; /* LEFT JOIN selects all records from the left table (table1) and the matching records from the right table (table2) */ SELECT column_name FROM table1 LEFT JOIN table2 ON table1.column_name = table2.column_name; /* RIGHT JOIN selects all records from the right table (table2) and the matching records from the left table (table1) */ SELECT column_name FROM table1 RIGHT JOIN table2 ON table1.column_name = table2.column_name; /* FULL OUTER JOIN returns all records when there is a match in left (table1) OR right (table2) table records -- FULL OUTER JOIN == FULL JOIN */ SELECT column_name FROM table1 FULL OUTER JOIN table2 ON table1.column_name = table2.column_name WHERE condition; /* a self join is a regular join, but the table is joined with itself */ SELECT column_name FROM table1 T1, table2 T2 -- T1, T2 are two aliases of table 1 and table 2 WHERE condition /* SQL Self Join Example: matching customers from the same city */ SELECT A.CustomerName AS CustomerName1, B.CustomerName AS CustomerName2, A.City FROM Customers A, Customers B WHERE A.CustomerID &lt;&gt; B.CustomerID -- &lt;&gt; stands for not equal AND A.City = B.City ORDER BY A.City; 4.2.3 UNION Operator UNION discards duplicates while UNION ALL does not the UNION operator is used to combine the result-set of two or more SELECT statements Every SELECT statement within UNION must have the same number of columns The columns must also have similar data types The columns in every SELECT statement must also be in the same order /* UNION : selects only distinct values by default */ SELECT column_name(s) FROM table1 UNION SELECT column_name(s) FROM table2; /* UNION ALL : allows duplicate values */ SELECT column_name(s) FROM table1 UNION ALL SELECT column_name(s) FROM table2; /* example1: returns the German cities (duplicate values also) from both the customers and the suppliers table */ SELECT City, Country FROM Customers WHERE Country=&#39;Germany&#39; UNION ALL SELECT City, Country FROM Suppliers WHERE Country=&#39;Germany&#39; ORDER BY City; 4.2.4 CASE statements can be used to create columns (new variables) for categorizing data filtering data aggregating data based on results of a logical test e.g. COUNT(CASE statement)–&gt;returns the number of rows returned by case statements instead of string / text similar aggregations include SUM/AVG/ROUND(AVG(…), digits) Percentages with CASE and AVG SELECT column1, ROUND(AVG(CASE WHEN condition1 AND condition2 THEN 0 WHEN condition1 AND condition3 THEN 1 END), 2) AS pct_column, FROM table1 GROUP BY column1 SELECT id, home_goal, away_goal, CASE WHEN home_goal &gt; away_goal THEN &#39;Home Team Win&#39; WHEN home_goal &lt; away_goal THEN &#39;Away Team Win&#39; ELSE &#39;Tie&#39; END AS outcome /* ELSE NULL AS outcome --&gt; if everything else should be N.A. END AS outcome --&gt; if we want to exclude every other conditions END IS NOT NULL --&gt; keep all clauses excluding missing values*/ FROM match WHERE season = &#39;2013/2014&#39;; /* Example 1: CASE WHEN + COUNT GROUP BY */ -- Identify the home team as Bayern Munich, Schalke 04, or neither SELECT CASE WHEN hometeam_id = 10189 THEN &#39;FC Schalke 04&#39; WHEN hometeam_id = 9823 THEN &#39;FC Bayern Munich&#39; ELSE &#39;Other&#39; END AS home_team, COUNT(id) AS total_matches FROM matches_germany -- Group by the CASE statement alias GROUP BY home_team; /* Example 2: CASE WHEN + LEFT JOIN + WHERE */ SELECT m.date, t.team_long_name AS opponent, -- Complete the CASE statement with an alias CASE WHEN m.home_goal &gt; away_goal THEN &#39;Barcelona win!&#39; WHEN m.home_goal &lt; away_goal THEN &#39;Barcelona loss :(&#39; ELSE &#39;Tie&#39; END AS outcome FROM matches_spain AS m LEFT JOIN teams_spain AS t ON m.awayteam_id = t.team_api_id -- Filter for Barcelona as the home team WHERE m.hometeam_id = 8634; 4.2.5 TEXT operations Select names starting with vowels SELECT column FROM table -- start with vowels WHERE column LIKE &#39;[aeiou]%&#39;; -- end with vowels WHERE column LIKE &#39;%[aeiou]&#39; -- both start and end w/ vowels WHERE column LIKE &#39;[aeiou]%[aeiou]&#39; -- contains vowels in any positions WHERE column LIKE &#39;%[aeiou]%&#39;; -- if NOT containing such characters then simiply do NOT LIKE ... LIKE: Simple string pattern matching LIKE operators with ‘%’ and ‘_’ LIKE Operator Description WHERE column LIKE 'a%' Finds any values that start with “a” WHERE column LIKE '%a' Finds any values that end with “a” WHERE column LIKE '%or%' Finds any values that have “or” in any position WHERE column LIKE '_r%' Finds any values that have “r” in the second position WHERE column LIKE 'a_%' Finds any values that start with “a” and are at least 2 characters in length WHERE column LIKE 'a__%' Finds any values that start with “a” and are at least 3 characters in length WHERE column LIKE 'a%o' Finds any values that start with “a” and ends with “o” WHERE column LIKE '[aeiou]%' Finds any values that start with any characters in “a”, “e”, “i”, “o”, or “u” SELECT colunm, LEN(column) AS column_length -- returns # of chars LEFT(column, 20) AS first_20_left_column -- returns first 20 chars from the LEFT RIGHT(column, 20) AS last_20_column -- returns last 20 chars from the RIGHT CHARINDEX(&#39;_&#39;, column) AS char_location -- returns the index of a char/string in column SUBSTRING(column, start, length) AS target_section -- returns substring starting at location 12 and has length of 12 FROM table; /* REPLACE */ SELECT TOP(5) REPLACE(column, &#39;a&#39;,&#39;b&#39;) AS replaced_column_with_b -- replaces char &#39;a&#39; in column with char &#39;b&#39; for all first 5 rows FROM table; 4.2.6 Substituting NULL values using COALESCE in T-SQL COALESCE(value_1, value_2, value_3, ..., value_n) -- if value_n is NULL and value_2 is not NULL, return value_2 -- ... value_n can also be some column SELECT column1, column2 COALESCE(column1, column2, &#39;N/A&#39;) AS new_column FROM table1 -- using ISNULL() function to replace all mising values in one column with values in another column or some other specified value SELECT column1, ISNULL(column1, column2) AS new_column1 FROM table1 4.2.7 DATE DATEADD (DATEPART, number, date): Add or subtract datetime values —&gt; always returns a date DATEPART: Unit of measurement (DD, MM, etc.) number: an integer value to add date: a datetime value DATEDIFF (datepart, startdate, enddate): Obtain the difference between two datetime values —&gt; always returns a number datepart: unit of measurement (DD, MM, etc,) startdate: the starting date value enddate: the ending datetime value /* date math w/ DATEDIFF */ SELECT date1, date2, DATEDIFF(DD, date1, date2) AS diff_day, DATEDIFF(MM, date1, date2) AS diff_month, DATEDIFF(YYYY, date1, date2) AS diff_year FROM table1 /* date math w/ DATEADD */ SELECT date1, DATEADD(DD, 7, date1) AS date_after_a_week FROM table1 4.2.8 ROUND and TRUNCATE /* IN T-SQL */ -- round(17.8, 0) --&gt; 18 while truncate rounds 17.8 to 17 SELECT column1, ROUND(column2, 0) AS RoundingtoWhole, ROUND(column2, 0, 1) AS Truncating -- adding a third parameter 1 to round for truncating FROM table1 OTHER MATH functions ABS(): absolute value SQRT(): square root | SQUARE(): square LOG(column, digit): returns the LOG with base # of digit 4.3 Advanced SQL - loops/CTE/Windows 4.3.1 WHILE Loops &amp; DECLARE Assigning values to variables and write loops -- Declare the variable DECLARE @my_var INT -- Use SET a value to the variable SET @my_var = 1 -- Show the value SELECT @my_var -- Specify the condition of the WHILE loop WHILE @my_var &lt; 10 -- Begin the code to execude insde the WHILE loop BEGIN -- Keep incrementing the value of @my_var SET @my_var = @my_var + 1 -- Check if @my_var is equal to 4 IF @my_var = 4 -- When my_var is 4 then break the loop BREAK -- End WHILE lopp END -- View the value after the loop SELECT @my_var 4.3.2 Derived Tables another name for a query acting as a table and are commonly used to do aggregations in T-SQL use derived tables when we want to break down a complex query into smaller steps great solution if we want to create intermediate calculations needed to be used in a larger query SELECT a.* FROM Kidney a -- This derived table computes the Average age are joined to the actual table JOIN (SELECT AVG(age) AS AverageAge FROM kidney) b ON a.Age = b.AverageAge -- a &amp; b are aliases for table Kidney and our derived table 4.3.3 CTE (Common Table Expressions) another type of derived table can be used multiple times in a query and are defined like a table -- CTE definitions start with the keyword WITH -- Followed by the CTE names and the columns it contains WITH CTEName (Co1, Col2) AS -- Define the CTE query ( -- the two columns from the definition above SELECT Col1, Col2 FROM TableName ) /* CTEs in T-SQL example */ -- Create a CTE to get the Maximum BloodPressure by Type WITH BloodPressureAge(Age, MaxBloodPressure) AS (SELECT Age, MAX(BloodPressure) AS MaxBloodPressure FROM Kidney GROUP BY Age) -- Create a query to use the CTE as a table SELECT a.Age, MIN(a.BloodPressure), b.MaxBloodPressure FROM Kidney a -- join the CTE with the table JOIN BloodPressureAge b ON a.Age = b.Age GROUP BY a.Age, b.MaxBloodPressure 4.3.4 Window Functions in SQL Create the window with OVER clause PARTITION BY creates the frame If you do not include PARTITION BY the frame is the entire table Allows aggregations to be created at the same time as the window -- Create a Window data grouping SELECT SalesPerson, SalesYear, CurrentQuota, SUM(CurrentQuota) OVER (PARTITION BY SalesYear ORDER BY SalesYear) AS YearlyTotal, ModifiedDate AS ModDate FROM SaleGoal /* the above example partitions the table by SalesYear and uses the windowing function SUM to add up every row of the CurrentQuota column in the window to provide a total for the entire window in the YearTotal column. When the year changes, the value in the YearTotal column changes showing the total for the next year becuz the window is partitioned by sales year. */ 4.3.5 Windows functions Cheatsheet Col1 Col2 ROW_NUMBER() Displays the unique number/index of a given row (no duplicates as compared to rank/dense_rank); starts are 1 and numbers the rows according to the ORDER BY part of window statements. RANK() Gives the identical rows a rank of 2, then skip ranks 3 and 4, so next rank would be 5. DENSE_RANK() Also gives identical rows a rank of 2, but the following rank would be 3 – no ranks would be skipped. NTILE(*# of buckets*) Identify what percentile (or quantile, or any other subdivison) a given row falls into. LAG(column, *# of rows*) Creates columns that pull previous values from other rows (second parameter specifies how many rows we need to pull) LEAD(column, *# of rows*) Creates columns that pull following/next values from other rows (second parameter specifies how many rows we need to pull) SUM() | COUNT() | AVG() | STDEV() Creates columns that calculate corresponding values based on mathematical operations 4.3.5.1 Getting first/last and next/previous values FIRST_VALUE() returns the first values in the window LAST_VALUE() returns the last values in the window --&gt; becuz we are trying to find a specific record in a window, the position of the records must be specified using the ORDER BY command. -- Select the columns SELECT SalesPerson, SalesYear, CurrentQuota, -- First value from every window FIRST_VALUE(CurrentQuota) OVER (PARTITION BY SalesYear ORDER BY ModifiedDate) AS StartQuota, -- Last value from every window LAST_VALUE(CurrentQuota) OVER (PARTITION BY SalesYear ORDER BY ModifiedDate) AS EndQuota, ModifiedDate as ModDate FROM SaleGoal Getting the next value with LEAD() and previous value with LAG() provides the ability to query the value from NEXT or PREVIOUS row also requires the use of ORDER BY to order the rows /* getting next value */ SELECT SalesPerson, SalesYear, CurrentQuota, -- Create a window function to get values from next row LEAD(CurrentQuota) -- use LAG(...) if need previous value OVER (PARTITION BY SalesYear ORDER BY ModifiedDate) AS NextQuota, ModifiedDate as ModDate FROM SaleGoal 4.3.5.2 Adding row numbers ROW_NUMBER(): sequentially numbers the rows in the window ORDER BY is required when using ROW_NUMBER() /* example of using ROW_NUMBER() to assign a new row number for each row in the window */ SELECT SalesPerson, SalesYear, CurrentQuota, ROW_NUMBER() OVER (PARTITION BY SalesPerson ORDER BY SalesYear) AS QuotabySalesPerson FROM SaleGoal 4.3.5.3 Using windows for Statistical Functions STDEV(): calculates the standard deviation SELECT SalesPerson, SalesYear, CurrentQuota, STDEV(CurrentQuota) OVER () AS StandardDev, -- do not include partition by if we are calculating for the entire table ModifiedDate AS ModDate FROM SaleGoal Calculating the mode: 1) create a CTE containing an ordered count of values using ROW_NUMBER(); 2) write a query using the CTE to pick the value with the highest row number -- Create a CTE called QuotaCount WITH QuotaCount AS ( SELECT SalesPerson, SalesYear, CurrentQuota, ROW_NUMBER() -- creating ordered count of values OVER (PARTITION BY CurrentQuota ORDER BY CurrentQuota) AS QuotaList FROM SaleGoal ) -- select everything from CTE SELECT * FROM QuotaCount -- write a query using CTE to pick the value with highest count (i.e. row number) SELECT CurrentQuota, QuotaList AS Mode FROM QuotaCount WHERE QuataList IN (SELECT MAX(QuotaList) FROM QuotaCount) -- select value in maximum count 4.3.6 Defining a window alias Example: SELECT column1, column2, NTILE(4) OVER (PARTITION BY column1 ORDER BY column2) AS quartile, NTILE(5) OVER (PARTITION BY column1 ORDER BY column2) AS quintile, NTILE(100) OVER (PARTITION BY column1 ORDER BY column2) AS percentile FROM table_name WHERE condition(s) ORDER BY column1, column2 Re-written example using window alias SELECT column1, column2 NTILE(4) OVER ntile_window AS quartile, NTILE(5) OVER ntile_window AS quintile, NTILE(100) OVER ntile_window AS percentile FROM table_name WHERE condition(s) /* NOTE if include the WINDOW clause, should always come AFTER the WHERE clause */ WINDOW ntile_window AS (PARTITION BY column1 ORDER BY column2) ORDER BY column1, column2 "],["cs145-dbs-data-systems.html", "Chapter 5 CS145 — DBs &amp; Data Systems 5.1 Introduction — DB overview 5.2 System Primer 5.3 ", " Chapter 5 CS145 — DBs &amp; Data Systems 5.1 Introduction — DB overview Applications of DBs and Data Systems Properties of general DBs, special-purpose DBs, data lakes Unpack a DB: Example of a mobile game using a DB For Whom and Why? Sample data architectures Goal of standard databases Platform to store, manage data (read/learn/modify) —&gt; supporting scale/speed/stability/evolution… Goals of special databases DBs are often optimized for key use cases store current data (e.g. lot of leads) optimize historical data (e.g. logs) run batch workloads (training) Data System “v1” on cloud log user actions store in DB, after ETL run queries in a peta scale analytcis system (BigQuery) visualize query results 5.1.1 Project goals Run queries on public datasets Explore/Visualize public datasets Predict using Machine Learning Full Query-Visualize-Learn data cycle on cloud stack 5.1.2 IO Blocks for Efficiency KEY CONCEPTS Data is stored in Blocks (aka “partition”) Sequential IO is 10x-100x+ faster than “many” random IO e.g. 1 MB (located sequentially) versus 1 Million bytes in random locations HDDs/SSDs copy sequential “big” blocks of bytes to/from RAM 5.1.3 Basic System Numbers Access Latency (secs) = Time to access Block’s start location Scan Throughput (GB/sec) = Speed to Scan + Copy data to RAM *Note: WHY are they different? Digital (e.g. SSDs and RAM) vs Analog (e.g. HDD seeks) Distance from CPU Access Latency (sec) Scan Throughput (GB/sec) What you get for ~100 RAM ~100 nanosec ~100 GB/sec High-end SSD HDD Seek (hard disk) Machines M1 TO M2 (network) 5.1.4 IO Cost Model Total time to ReadData = Access Latency * M + DataSize / ScanThroughput DataSize = data size M = # of non-contiguous Blocks AccessLatency = Time to access Block ScanThroughput = Speed to copy/scan to RAM 5.2 System Primer Clouds of Machine 5.3 5.3.1 Data Independence Logical data independence —&gt; we can add a new column or attribute w/o rewriting the application. Physical data independence —&gt; you should NOT care which disks/machines the data are stored on. 5.3.2 Data Model Relational model (aka Tables) simple and most popular elegant algebra (E.F. Codd et al) Structured data (e.g. a typed Schema) Hierarchical model (aka JSON-like Tree) semi-structured data Example on Tradeoffs Key “CS” ideas: structured, or semi-structured w/ lots of optional fields? how deep is the tree structure? what kinds of queries and updates do you want to run? (e.g. customer-oriented queries? Purchase-oriented queries?) Rough rule of thumb Relational: Google Ads Hierarchical: document search. Lots of optional fields? many levels deep. Mostly search oriented around the top level of doc. "],["machine-learning-models.html", "Chapter 6 Machine Learning Models 6.1 Introduction 6.2 Supervised Learning", " Chapter 6 Machine Learning Models references: cs 229 Stanford 6.1 Introduction 6.1.1 What is Machine Learning General Definition: &gt; [Machine Learning is the] field of study that gives computers the ability to learn without being explicitly programmed. &gt; &lt;footer&gt;--- Arthur Samuel, 1959&lt;/footer&gt; Engineering-oriented Definition: &gt; A computer program is said to learn from experience E with respect to some task T and some performance measure P, if its performance on T, as measured by P, improves with experience E. &gt; &lt;footer&gt;--- Tom Mitchell, 1997&lt;/footer&gt; 6.1.2 Why do we use Machine Learning? Machine learning techniques are great for: Problems whose existing solutions require a lot of fine-tuning and long list of rules: one ML algorithm can often simplify code and perform better than traditional approach. Complex problems for which using a traditional approach yields no good solution Fluctuating environments: A ML system can adapt to new data Getting insights about complex problems and large amount of data (data mining). 6.1.3 Examples of ML applications in industries ML technique Problems Classification Analyzing images of products on a production line to automatically classify them (with CNNs) Classifying new articles (NLP + RNNs/CNNs/Transformers) Automatically flagging offensive comments on discussion forums (text classification w/ NLP tools) Market segmentation / social network analysis Regression Forecasting company revenue based on performance metrics (with Linear/Polynomial Regression / a regression SVM / a regression Random Forest / RNN) Clustering Client segmentation based on purchases to derive marketing strategy for each segment Anomaly Detection Detecting credit card fraud Recommender System Recommending a product that clients may be interested in based on past purchases 6.1.4 Types of Machine Learning Systems Criteria: trained with human supervision? —&gt; supervised, unsupervised, semisupervised, Reinforcement Learning can learn incrementally on the fly? —&gt; online vs. batch learning work by simply comparing new data points to know data points OR by detecting patterns in training data and building a predictive model? —&gt; instance-based vs. model-based learning 6.1.4.1 Supervised Learning Most important Supervised Learning algorithms: Regression Linear Regression Logistic Regression Classification k-Nearest Neighbors Support Vector Machines (SVM) Decision Trees and Random Forests Neural Networks 6.1.4.2 Unsupervised Learning --&gt; unlabeled data (only x but no y) Most important Unsupervised Learning algorithms: Clustering —&gt; e.g. run a clustering to detect groups of similar observations where we do not need to tell the algorithm which group an observation belongs to: it finds those connections without human supervision. K-Means DBSCAN Hierarchical Cluster Analysis Anomaly detection and novelty detection One-class SVM Isolation Forest Visualization and Dimensionality reduction —&gt; feed visualization algorithms complex and unlabeled data, and they output a 2D or 3D representation of our data that can be easily plotted —&gt; helps us understand how data is organized and perhaps identify unsuspected patterns. | Dimensionality reduction aims at simplifying data without losing too much information by merging correlated features into one for example (also the process of feature extraction). Principal Component Analysis (PCA) Kernel PCA Locally Linear Embedding (LLE) t-Distributed Stochastic Neighbor Embedding (t-SNE) Association rule learning —&gt; dig into large amounts of data and discover interesting relations between attributes Apriori Eclat 6.1.4.3 Semisupervised Learning Since labeling data is usually time-consuming and costly, we will often have plenty of unlabeled instances, and few labeled instances. Some algorithms can deal with data that’s partially labeled. Most semisupervised learning algorithms are combinations of unsupervised and supervised algorithms. For example, deep belief networks (DBNs) are based on unsupervised components called restricted Boltzmann machines (RBMs) stacked on top of one another. RBMs are trained sequentially in an unsupervised manner, and then the whole system is fine-tuned using supervised learning techniques. 6.1.4.4 Reinforcement Learning In RL, the learning system, called an agent in this context, can observe the environment, select and perform actions, and get rewards in turn (or penalties in the form of negative rewards). It must then learn by itself what is the best strategy, called a policy, to get the most reward over time. A policy defines what action the agent should choose when it is in a given situation. 6.1.4.5 Batch and Online Learning Batch Learning In batch learning, the system is incapable of learning incrementally: it must be trained using all the available data. Online learning In online learning, you train the system incrementally by feeding it data instances sequentially, either individually or in small groups called mini-batches. Each learning step is fast and cheap, so the system can learn about new data on the fly, as it arrives. 6.1.5 Practical ML advice 6.2 Supervised Learning Terminology: Features: \\(x^{(i)}\\) denotes the “input” variable Target: \\(y^{(i)}\\) denotes the “output” (i.e. outcome to predict) Training Example: A pair \\((x^{(i)}, y^{(i)})\\) Training set: a list of \\(n\\) training examples: \\(\\{(x^{(i)},y^{(i)}); i = 1, …, n\\}\\) Space: \\(\\mathcal{X}\\) denotes the space of input values; \\(\\mathcal{Y}\\) denotes the space of output values. Usually, \\(\\mathcal{X}=\\mathcal{Y}=\\mathcal{R}.\\) 6.2.0.1 Formal description of supervised learning problem: Given a training set, to learn a function \\(h: \\mathcal{X} \\mapsto \\mathcal{Y}\\) so that \\(h(x)\\) is a “good” predictor for the corresponding value of $y$. For historical reasons, this function \\(h\\) is called a hypothesis. Continuous target —&gt; regression; discrete target —&gt; classification "],["product-sense.html", "Chapter 7 Product Sense", " Chapter 7 Product Sense "],["404.html", "Page not found", " Page not found The page you requested cannot be found (perhaps it was moved or renamed). You may want to try searching to find the page's new location, or use the table of contents to find the page you are looking for. "]]
