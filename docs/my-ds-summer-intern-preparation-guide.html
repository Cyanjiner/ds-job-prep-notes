<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>Chapter 8 My DS Summer Intern Preparation Guide | DS Intern/NG Job Application Prep Notes</title>
  <meta name="description" content="Chapter 8 My DS Summer Intern Preparation Guide | DS Intern/NG Job Application Prep Notes" />
  <meta name="generator" content="bookdown 0.28 and GitBook 2.6.7" />

  <meta property="og:title" content="Chapter 8 My DS Summer Intern Preparation Guide | DS Intern/NG Job Application Prep Notes" />
  <meta property="og:type" content="book" />
  
  
  

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Chapter 8 My DS Summer Intern Preparation Guide | DS Intern/NG Job Application Prep Notes" />
  
  
  

<meta name="author" content="Jiner Zheng" />


<meta name="date" content="2022-09-27" />

  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="product-sense.html"/>

<script src="libs/jquery-3.6.0/jquery-3.6.0.min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/fuse.js@6.4.6/dist/fuse.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />








<link href="libs/anchor-sections-1.1.0/anchor-sections.css" rel="stylesheet" />
<link href="libs/anchor-sections-1.1.0/anchor-sections-hash.css" rel="stylesheet" />
<script src="libs/anchor-sections-1.1.0/anchor-sections.js"></script>


<style type="text/css">
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { color: #008000; } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { color: #008000; font-weight: bold; } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>


<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">DS Interview Prep Notes</a></li>

<li class="divider"></li>
<li class="chapter" data-level="1" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i><b>1</b> Summary resources for DS learning</a>
<ul>
<li class="chapter" data-level="1.1" data-path="index.html"><a href="index.html#statistics-probability-and-ab-testing"><i class="fa fa-check"></i><b>1.1</b> Statistics, Probability, and A/B Testing</a>
<ul>
<li class="chapter" data-level="1.1.1" data-path="index.html"><a href="index.html#stanford-courses-non-educ"><i class="fa fa-check"></i><b>1.1.1</b> Stanford Courses (NON-EDUC):</a></li>
<li class="chapter" data-level="1.1.2" data-path="index.html"><a href="index.html#online-resources"><i class="fa fa-check"></i><b>1.1.2</b> Online Resources</a></li>
</ul></li>
<li class="chapter" data-level="1.2" data-path="index.html"><a href="index.html#sql-r-python-visualization-tools"><i class="fa fa-check"></i><b>1.2</b> SQL / R / Python / Visualization Tools</a></li>
<li class="chapter" data-level="1.3" data-path="index.html"><a href="index.html#machine-learning-resources"><i class="fa fa-check"></i><b>1.3</b> Machine Learning resources</a>
<ul>
<li class="chapter" data-level="1.3.1" data-path="index.html"><a href="index.html#stanford-classes"><i class="fa fa-check"></i><b>1.3.1</b> Stanford Classes:</a></li>
<li class="chapter" data-level="1.3.2" data-path="index.html"><a href="index.html#online-resources-1"><i class="fa fa-check"></i><b>1.3.2</b> Online Resources</a></li>
</ul></li>
<li class="chapter" data-level="1.4" data-path="index.html"><a href="index.html#interview-questions-resume"><i class="fa fa-check"></i><b>1.4</b> Interview Questions &amp; Resume</a></li>
</ul></li>
<li class="chapter" data-level="2" data-path="statistics-and-probability.html"><a href="statistics-and-probability.html"><i class="fa fa-check"></i><b>2</b> Statistics and Probability</a>
<ul>
<li class="chapter" data-level="2.1" data-path="statistics-and-probability.html"><a href="statistics-and-probability.html#important-concepts-to-review"><i class="fa fa-check"></i><b>2.1</b> IMPORTANT Concepts to review</a>
<ul>
<li class="chapter" data-level="2.1.1" data-path="statistics-and-probability.html"><a href="statistics-and-probability.html#key-terms-for-variability-metrics"><i class="fa fa-check"></i><b>2.1.1</b> Key terms for Variability Metrics</a></li>
</ul></li>
<li class="chapter" data-level="2.2" data-path="statistics-and-probability.html"><a href="statistics-and-probability.html#designing-studies"><i class="fa fa-check"></i><b>2.2</b> Designing Studies</a>
<ul>
<li class="chapter" data-level="2.2.1" data-path="statistics-and-probability.html"><a href="statistics-and-probability.html#identifying-variables-type"><i class="fa fa-check"></i><b>2.2.1</b> Identifying variables type:</a></li>
<li class="chapter" data-level="2.2.2" data-path="statistics-and-probability.html"><a href="statistics-and-probability.html#classify-study-type-as-ovbservational-or-experimental"><i class="fa fa-check"></i><b>2.2.2</b> Classify study type as ovbservational or experimental</a></li>
<li class="chapter" data-level="2.2.3" data-path="statistics-and-probability.html"><a href="statistics-and-probability.html#sampling-techniques"><i class="fa fa-check"></i><b>2.2.3</b> Sampling Techniques</a></li>
<li class="chapter" data-level="2.2.4" data-path="statistics-and-probability.html"><a href="statistics-and-probability.html#principles-of-experimental-designcontrol-randomize-replicate-and-blockand-their-purposes"><i class="fa fa-check"></i><b>2.2.4</b> Principles of Experimental Design—Control, Randomize, Replicate, and Block—and their purposes</a></li>
<li class="chapter" data-level="2.2.5" data-path="statistics-and-probability.html"><a href="statistics-and-probability.html#random-sampling-vs.-random-assignment"><i class="fa fa-check"></i><b>2.2.5</b> Random Sampling vs. Random Assignment</a></li>
<li class="chapter" data-level="2.2.6" data-path="statistics-and-probability.html"><a href="statistics-and-probability.html#hypothesis-tests-and-resampling"><i class="fa fa-check"></i><b>2.2.6</b> Hypothesis Tests and Resampling</a></li>
<li class="chapter" data-level="2.2.7" data-path="statistics-and-probability.html"><a href="statistics-and-probability.html#statistical-significance-and-p-values"><i class="fa fa-check"></i><b>2.2.7</b> Statistical Significance and p-values</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="3" data-path="ab-testing.html"><a href="ab-testing.html"><i class="fa fa-check"></i><b>3</b> A/B Testing</a>
<ul>
<li class="chapter" data-level="3.1" data-path="ab-testing.html"><a href="ab-testing.html#what-is-ab-testing"><i class="fa fa-check"></i><b>3.1</b> What is A/B testing?</a></li>
<li class="chapter" data-level="3.2" data-path="ab-testing.html"><a href="ab-testing.html#what-you-cant-do-with-ab-testing"><i class="fa fa-check"></i><b>3.2</b> What you can’t do with A/B testing?</a></li>
<li class="chapter" data-level="3.3" data-path="ab-testing.html"><a href="ab-testing.html#defining-the-hypothesis"><i class="fa fa-check"></i><b>3.3</b> Defining the hypothesis</a></li>
<li class="chapter" data-level="3.4" data-path="ab-testing.html"><a href="ab-testing.html#defining-metrics-and-gathering-data"><i class="fa fa-check"></i><b>3.4</b> Defining Metrics and Gathering Data</a>
<ul>
<li class="chapter" data-level="3.4.1" data-path="ab-testing.html"><a href="ab-testing.html#high-level-concepts-for-metrics"><i class="fa fa-check"></i><b>3.4.1</b> High-Level concepts for metrics</a></li>
<li class="chapter" data-level="3.4.2" data-path="ab-testing.html"><a href="ab-testing.html#methods-for-coming-up-w-proxy-metrics-or-validating-metrics"><i class="fa fa-check"></i><b>3.4.2</b> Methods for Coming up w/ Proxy Metrics or Validating Metrics</a></li>
<li class="chapter" data-level="3.4.3" data-path="ab-testing.html"><a href="ab-testing.html#gathering-additional-data"><i class="fa fa-check"></i><b>3.4.3</b> Gathering Additional Data</a></li>
<li class="chapter" data-level="3.4.4" data-path="ab-testing.html"><a href="ab-testing.html#segmenting-and-filtering-data"><i class="fa fa-check"></i><b>3.4.4</b> Segmenting and Filtering Data</a></li>
</ul></li>
<li class="chapter" data-level="3.5" data-path="ab-testing.html"><a href="ab-testing.html#designing-an-ab-test"><i class="fa fa-check"></i><b>3.5</b> Designing an A/B test</a>
<ul>
<li class="chapter" data-level="3.5.1" data-path="ab-testing.html"><a href="ab-testing.html#summary-workflow-of-ab-testing"><i class="fa fa-check"></i><b>3.5.1</b> Summary workflow of A/B testing:</a></li>
</ul></li>
<li class="chapter" data-level="3.6" data-path="ab-testing.html"><a href="ab-testing.html#step1-choose-and-characterize-metrics-for-both-sanity-check-and-evaluation"><i class="fa fa-check"></i><b>3.6</b> Step1: Choose and characterize metrics for both <code>sanity check and evaluation</code></a></li>
<li class="chapter" data-level="3.7" data-path="ab-testing.html"><a href="ab-testing.html#step-2-choose-significance-level-statistical-power-and-practical-significance-level"><i class="fa fa-check"></i><b>3.7</b> Step 2: Choose significance level, statistical power and practical significance level</a></li>
<li class="chapter" data-level="3.8" data-path="ab-testing.html"><a href="ab-testing.html#step-3-calculate-required-sample-size"><i class="fa fa-check"></i><b>3.8</b> Step 3: Calculate required sample size</a></li>
<li class="chapter" data-level="3.9" data-path="ab-testing.html"><a href="ab-testing.html#step-4-take-sample-for-controltreatment-groups-and-run-the-test"><i class="fa fa-check"></i><b>3.9</b> Step 4: Take sample for control/treatment groups and run the test</a></li>
<li class="chapter" data-level="3.10" data-path="ab-testing.html"><a href="ab-testing.html#step-5-analyze-the-results-and-draw-conclusions"><i class="fa fa-check"></i><b>3.10</b> Step 5: Analyze the results and draw conclusions</a>
<ul>
<li class="chapter" data-level="3.10.1" data-path="ab-testing.html"><a href="ab-testing.html#first-step-sanity-check"><i class="fa fa-check"></i><b>3.10.1</b> First step — Sanity Check</a></li>
<li class="chapter" data-level="3.10.2" data-path="ab-testing.html"><a href="ab-testing.html#second-step-analyze-the-results"><i class="fa fa-check"></i><b>3.10.2</b> Second step — Analyze the Results</a></li>
<li class="chapter" data-level="3.10.3" data-path="ab-testing.html"><a href="ab-testing.html#last-step-draw-conclusions"><i class="fa fa-check"></i><b>3.10.3</b> Last step — Draw Conclusions</a></li>
</ul></li>
<li class="chapter" data-level="3.11" data-path="ab-testing.html"><a href="ab-testing.html#other-things-to-keep-in-mind"><i class="fa fa-check"></i><b>3.11</b> Other things to keep in mind</a></li>
</ul></li>
<li class="chapter" data-level="4" data-path="database-management-and-data-systems-sql.html"><a href="database-management-and-data-systems-sql.html"><i class="fa fa-check"></i><b>4</b> Database Management and Data Systems (SQL)</a>
<ul>
<li class="chapter" data-level="4.1" data-path="database-management-and-data-systems-sql.html"><a href="database-management-and-data-systems-sql.html#crud-create-read-update-delete-operations"><i class="fa fa-check"></i><b>4.1</b> CRUD (create, read, update, delete) Operations</a>
<ul>
<li class="chapter" data-level="4.1.1" data-path="database-management-and-data-systems-sql.html"><a href="database-management-and-data-systems-sql.html#create-databases-tables-views-users-permissions-security-groups"><i class="fa fa-check"></i><b>4.1.1</b> CREATE —&gt; Databases | Tables | Views | Users | Permissions | Security Groups</a></li>
<li class="chapter" data-level="4.1.2" data-path="database-management-and-data-systems-sql.html"><a href="database-management-and-data-systems-sql.html#insert-insert-new-records-into-existing-database-tables"><i class="fa fa-check"></i><b>4.1.2</b> INSERT, — insert new records into existing database tables</a></li>
<li class="chapter" data-level="4.1.3" data-path="database-management-and-data-systems-sql.html"><a href="database-management-and-data-systems-sql.html#update-amend-existing-database-records"><i class="fa fa-check"></i><b>4.1.3</b> UPDATE — Amend existing database records</a></li>
<li class="chapter" data-level="4.1.4" data-path="database-management-and-data-systems-sql.html"><a href="database-management-and-data-systems-sql.html#delete-delete-existing-records-from-tables"><i class="fa fa-check"></i><b>4.1.4</b> DELETE — delete existing records from tables</a></li>
<li class="chapter" data-level="4.1.5" data-path="database-management-and-data-systems-sql.html"><a href="database-management-and-data-systems-sql.html#declare-variables-so-it-will-be-easier-to-use-in-later-conditions-without-repetitively-calling-the-same-values"><i class="fa fa-check"></i><b>4.1.5</b> Declare Variables —&gt; so it will be easier to use in later conditions without repetitively calling the same values</a></li>
<li class="chapter" data-level="4.1.6" data-path="database-management-and-data-systems-sql.html"><a href="database-management-and-data-systems-sql.html#temporary-tables"><i class="fa fa-check"></i><b>4.1.6</b> Temporary tables</a></li>
<li class="chapter" data-level="4.1.7" data-path="database-management-and-data-systems-sql.html"><a href="database-management-and-data-systems-sql.html#read-view"><i class="fa fa-check"></i><b>4.1.7</b> READ | VIEW</a></li>
</ul></li>
<li class="chapter" data-level="4.2" data-path="database-management-and-data-systems-sql.html"><a href="database-management-and-data-systems-sql.html#exploratory-data-analysis-in-sql-t-sql"><i class="fa fa-check"></i><b>4.2</b> Exploratory Data Analysis in SQL (T-SQL)</a>
<ul>
<li class="chapter" data-level="4.2.1" data-path="database-management-and-data-systems-sql.html"><a href="database-management-and-data-systems-sql.html#group-by-having-where"><i class="fa fa-check"></i><b>4.2.1</b> GROUP BY | HAVING | WHERE</a></li>
<li class="chapter" data-level="4.2.2" data-path="database-management-and-data-systems-sql.html"><a href="database-management-and-data-systems-sql.html#join-examples"><i class="fa fa-check"></i><b>4.2.2</b> JOIN examples</a></li>
<li class="chapter" data-level="4.2.3" data-path="database-management-and-data-systems-sql.html"><a href="database-management-and-data-systems-sql.html#union-operator"><i class="fa fa-check"></i><b>4.2.3</b> UNION Operator</a></li>
<li class="chapter" data-level="4.2.4" data-path="database-management-and-data-systems-sql.html"><a href="database-management-and-data-systems-sql.html#case-statements-can-be-used-to-create-columns-new-variables-for"><i class="fa fa-check"></i><b>4.2.4</b> CASE statements can be used to create columns (new variables) for</a></li>
<li class="chapter" data-level="4.2.5" data-path="database-management-and-data-systems-sql.html"><a href="database-management-and-data-systems-sql.html#text-operations"><i class="fa fa-check"></i><b>4.2.5</b> TEXT operations</a></li>
<li class="chapter" data-level="4.2.6" data-path="database-management-and-data-systems-sql.html"><a href="database-management-and-data-systems-sql.html#substituting-null-values-using-coalesce-in-t-sql"><i class="fa fa-check"></i><b>4.2.6</b> Substituting NULL values using COALESCE in T-SQL</a></li>
<li class="chapter" data-level="4.2.7" data-path="database-management-and-data-systems-sql.html"><a href="database-management-and-data-systems-sql.html#date"><i class="fa fa-check"></i><b>4.2.7</b> DATE</a></li>
<li class="chapter" data-level="4.2.8" data-path="database-management-and-data-systems-sql.html"><a href="database-management-and-data-systems-sql.html#round-and-truncate"><i class="fa fa-check"></i><b>4.2.8</b> ROUND and TRUNCATE</a></li>
</ul></li>
<li class="chapter" data-level="4.3" data-path="database-management-and-data-systems-sql.html"><a href="database-management-and-data-systems-sql.html#advanced-sql---loopsctewindows"><i class="fa fa-check"></i><b>4.3</b> Advanced SQL - loops/CTE/Windows</a>
<ul>
<li class="chapter" data-level="4.3.1" data-path="database-management-and-data-systems-sql.html"><a href="database-management-and-data-systems-sql.html#while-loops-declare"><i class="fa fa-check"></i><b>4.3.1</b> WHILE Loops &amp; DECLARE</a></li>
<li class="chapter" data-level="4.3.2" data-path="database-management-and-data-systems-sql.html"><a href="database-management-and-data-systems-sql.html#derived-tables"><i class="fa fa-check"></i><b>4.3.2</b> Derived Tables</a></li>
<li class="chapter" data-level="4.3.3" data-path="database-management-and-data-systems-sql.html"><a href="database-management-and-data-systems-sql.html#cte-common-table-expressions"><i class="fa fa-check"></i><b>4.3.3</b> CTE (Common Table Expressions)</a></li>
<li class="chapter" data-level="4.3.4" data-path="database-management-and-data-systems-sql.html"><a href="database-management-and-data-systems-sql.html#window-functions-in-sql"><i class="fa fa-check"></i><b>4.3.4</b> Window Functions in SQL</a></li>
<li class="chapter" data-level="4.3.5" data-path="database-management-and-data-systems-sql.html"><a href="database-management-and-data-systems-sql.html#windows-functions-cheatsheet"><i class="fa fa-check"></i><b>4.3.5</b> Windows functions Cheatsheet</a></li>
<li class="chapter" data-level="4.3.6" data-path="database-management-and-data-systems-sql.html"><a href="database-management-and-data-systems-sql.html#defining-a-window-alias"><i class="fa fa-check"></i><b>4.3.6</b> Defining a window alias</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="5" data-path="cs145-dbs-data-systems.html"><a href="cs145-dbs-data-systems.html"><i class="fa fa-check"></i><b>5</b> CS145 — DBs &amp; Data Systems</a>
<ul>
<li class="chapter" data-level="5.1" data-path="cs145-dbs-data-systems.html"><a href="cs145-dbs-data-systems.html#introduction"><i class="fa fa-check"></i><b>5.1</b> Introduction</a></li>
</ul></li>
<li class="chapter" data-level="6" data-path="machine-learning-models.html"><a href="machine-learning-models.html"><i class="fa fa-check"></i><b>6</b> Machine Learning Models</a>
<ul>
<li class="chapter" data-level="6.1" data-path="machine-learning-models.html"><a href="machine-learning-models.html#introduction-1"><i class="fa fa-check"></i><b>6.1</b> Introduction</a>
<ul>
<li class="chapter" data-level="6.1.1" data-path="machine-learning-models.html"><a href="machine-learning-models.html#what-is-machine-learning"><i class="fa fa-check"></i><b>6.1.1</b> What is Machine Learning</a></li>
<li class="chapter" data-level="6.1.2" data-path="machine-learning-models.html"><a href="machine-learning-models.html#why-do-we-use-machine-learning"><i class="fa fa-check"></i><b>6.1.2</b> Why do we use Machine Learning?</a></li>
<li class="chapter" data-level="6.1.3" data-path="machine-learning-models.html"><a href="machine-learning-models.html#examples-of-ml-applications-in-industries"><i class="fa fa-check"></i><b>6.1.3</b> Examples of ML applications in industries</a></li>
<li class="chapter" data-level="6.1.4" data-path="machine-learning-models.html"><a href="machine-learning-models.html#types-of-machine-learning-systems"><i class="fa fa-check"></i><b>6.1.4</b> Types of Machine Learning Systems</a></li>
<li class="chapter" data-level="6.1.5" data-path="machine-learning-models.html"><a href="machine-learning-models.html#practical-ml-advice"><i class="fa fa-check"></i><b>6.1.5</b> Practical ML advice</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="7" data-path="product-sense.html"><a href="product-sense.html"><i class="fa fa-check"></i><b>7</b> Product Sense</a></li>
<li class="chapter" data-level="8" data-path="my-ds-summer-intern-preparation-guide.html"><a href="my-ds-summer-intern-preparation-guide.html"><i class="fa fa-check"></i><b>8</b> My DS Summer Intern Preparation Guide</a>
<ul>
<li class="chapter" data-level="8.1" data-path="my-ds-summer-intern-preparation-guide.html"><a href="my-ds-summer-intern-preparation-guide.html#resume-related-technical-content-jiner-only"><i class="fa fa-check"></i><b>8.1</b> Resume related technical content –&gt; JINER only</a>
<ul>
<li class="chapter" data-level="8.1.1" data-path="my-ds-summer-intern-preparation-guide.html"><a href="my-ds-summer-intern-preparation-guide.html#intern1---statistical-consultant-r-tableau"><i class="fa fa-check"></i><b>8.1.1</b> Intern1 - Statistical Consultant (R, Tableau)</a></li>
<li class="chapter" data-level="8.1.2" data-path="my-ds-summer-intern-preparation-guide.html"><a href="my-ds-summer-intern-preparation-guide.html#intern2---data-science-intern-r-python"><i class="fa fa-check"></i><b>8.1.2</b> Intern2 - Data Science Intern (R, Python)</a></li>
<li class="chapter" data-level="8.1.3" data-path="my-ds-summer-intern-preparation-guide.html"><a href="my-ds-summer-intern-preparation-guide.html#intern3---data-science-intern"><i class="fa fa-check"></i><b>8.1.3</b> Intern3 - Data Science Intern</a></li>
<li class="chapter" data-level="8.1.4" data-path="my-ds-summer-intern-preparation-guide.html"><a href="my-ds-summer-intern-preparation-guide.html#capstone-research"><i class="fa fa-check"></i><b>8.1.4</b> Capstone research</a></li>
</ul></li>
<li class="chapter" data-level="8.2" data-path="my-ds-summer-intern-preparation-guide.html"><a href="my-ds-summer-intern-preparation-guide.html#sql-python-r-tableau"><i class="fa fa-check"></i><b>8.2</b> SQL | Python | R | Tableau</a>
<ul>
<li class="chapter" data-level="8.2.1" data-path="my-ds-summer-intern-preparation-guide.html"><a href="my-ds-summer-intern-preparation-guide.html#basic-statistics"><i class="fa fa-check"></i><b>8.2.1</b> Basic Statistics:</a></li>
</ul></li>
<li class="chapter" data-level="8.3" data-path="my-ds-summer-intern-preparation-guide.html"><a href="my-ds-summer-intern-preparation-guide.html#probability-usually-test-easy-medium-prob-questions"><i class="fa fa-check"></i><b>8.3</b> Probability: (usually test easy-medium prob questions)</a></li>
<li class="chapter" data-level="8.4" data-path="my-ds-summer-intern-preparation-guide.html"><a href="my-ds-summer-intern-preparation-guide.html#ml-theory-for-ds-modeling-job"><i class="fa fa-check"></i><b>8.4</b> ML Theory (for DS-Modeling job)</a></li>
<li class="chapter" data-level="8.5" data-path="my-ds-summer-intern-preparation-guide.html"><a href="my-ds-summer-intern-preparation-guide.html#ab-testing-and-product-sense"><i class="fa fa-check"></i><b>8.5</b> A/B Testing and Product Sense</a></li>
<li class="chapter" data-level="8.6" data-path="my-ds-summer-intern-preparation-guide.html"><a href="my-ds-summer-intern-preparation-guide.html#statistical-testing"><i class="fa fa-check"></i><b>8.6</b> Statistical Testing</a></li>
<li class="chapter" data-level="8.7" data-path="my-ds-summer-intern-preparation-guide.html"><a href="my-ds-summer-intern-preparation-guide.html#behavioral-questions"><i class="fa fa-check"></i><b>8.7</b> Behavioral Questions</a></li>
</ul></li>
<li class="divider"></li>
<li><a href="https://github.com/rstudio/bookdown" target="blank">Published with bookdown</a></li>
</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">DS Intern/NG Job Application Prep Notes</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="my-ds-summer-intern-preparation-guide" class="section level1 hasAnchor" number="8">
<h1><span class="header-section-number">Chapter 8</span> My DS Summer Intern Preparation Guide<a href="my-ds-summer-intern-preparation-guide.html#my-ds-summer-intern-preparation-guide" class="anchor-section" aria-label="Anchor link to header"></a></h1>
<p>KEY Concepts to review:</p>
<div id="resume-related-technical-content-jiner-only" class="section level2 hasAnchor" number="8.1">
<h2><span class="header-section-number">8.1</span> Resume related technical content –&gt; JINER only<a href="my-ds-summer-intern-preparation-guide.html#resume-related-technical-content-jiner-only" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<div id="intern1---statistical-consultant-r-tableau" class="section level3 hasAnchor" number="8.1.1">
<h3><span class="header-section-number">8.1.1</span> Intern1 - Statistical Consultant (R, Tableau)<a href="my-ds-summer-intern-preparation-guide.html#intern1---statistical-consultant-r-tableau" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<div id="short-description-of-the-project" class="section level4 hasAnchor" number="8.1.1.1">
<h4><span class="header-section-number">8.1.1.1</span> Short description of the project<a href="my-ds-summer-intern-preparation-guide.html#short-description-of-the-project" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>I was mainly responsive for conducting a statistical analysis research project on analyzing client behavior in The Connection. And The Connection is a statewide community-based human services agency that helps clients in their programs to solve problems of homeless, mental illness, substance use, and community justice rehabilitation. The main goal of my project was to analyze social and psychological factors associated with the likelihood of behavior incidents during clients’ participation in the Connection programming and also investigate what kinds of characteristics do they share in common and where do these clients locate after the programs.</p>
</div>
<div id="what-techniques-did-you-use-for-this-project" class="section level4 hasAnchor" number="8.1.1.2">
<h4><span class="header-section-number">8.1.1.2</span> What techniques did you use for this project?<a href="my-ds-summer-intern-preparation-guide.html#what-techniques-did-you-use-for-this-project" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>First, I performed data wrangling and data blending on about 10 data sets related to client behaviors or criminal incidents and designed 9 key metrics to evaluate clients’ social and psychological status, such as suicidal or homicidal risks, trauma history, or involvement and disruption from alcohol and drug use.</p>
<p>We also used multiple regression analyses to asses the relationship between clients’ incident score (which is a composite measure of their incident frequency and severity) and their social, psychological risk factors, while controlling for demographic factors.</p>
<p>The latent class analysis was also conducted for client profiling and identify three groups with different level of risks, where each client was assigned to a class based on the similarity of their pattern of response on the classification variables to other clients —&gt;</p>
<ul>
<li><p>data manipulation &amp; visualization methods / packages</p></li>
<li><p>multiple regression model</p></li>
<li><p>latent class analysis / k-means clustering</p></li>
<li><p>chi-square (goodness of fit, contigency)</p></li>
</ul>
</div>
</div>
<div id="intern2---data-science-intern-r-python" class="section level3 hasAnchor" number="8.1.2">
<h3><span class="header-section-number">8.1.2</span> Intern2 - Data Science Intern (R, Python)<a href="my-ds-summer-intern-preparation-guide.html#intern2---data-science-intern-r-python" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<div id="how-to-design-key-metrics" class="section level4 hasAnchor" number="8.1.2.1">
<h4><span class="header-section-number">8.1.2.1</span> how to design key metrics?<a href="my-ds-summer-intern-preparation-guide.html#how-to-design-key-metrics" class="anchor-section" aria-label="Anchor link to header"></a></h4>
</div>
<div id="etl-pipeline-and-r-shinyapp-dashboard" class="section level4 hasAnchor" number="8.1.2.2">
<h4><span class="header-section-number">8.1.2.2</span> ETL pipeline and R ShinyApp dashboard<a href="my-ds-summer-intern-preparation-guide.html#etl-pipeline-and-r-shinyapp-dashboard" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>references: <a href="https://www.databricks.com/glossary/extract-transform-load">Extract Transform Load (ETL)</a> | <a href="https://www.r-bloggers.com/2022/03/dashboards-in-r-shiny/">Dashboards in R Shiny</a></p>
<ul>
<li><p><strong><code>ETL Pipeline:</code></strong> ETL stands for <strong><code>"Extract, Transform, Load"</code></strong> so it mainly includes these three independent processes of data integration to pull data from one database and move it to another. Once loaded, data can be used for reporting, analysis, and deriving actionable business insights.</p></li>
<li><p><strong><code>R Shiny Dashboard:</code></strong> let you access complete web application framework within R environment. Easily turn your work in R including analyses, visualizations, machine learning models, and more into web applications that deliver value to business.</p>
<ul>
<li><p>It also enables <strong>easy <code>customization of dashboard</code></strong> using custom HTML, CSS, Javascript and so on to create a unique, branded dashboard that’s not possible with other BI software suite, where we can add colors, logos, fonts and more to better represent our business.</p></li>
<li><p>It is also <strong><code>open source and cost-friendly</code></strong> compared to its counterparts like Power BI or Tableau.</p></li>
</ul></li>
</ul>
</div>
<div id="user-based-collaborative-filtering-algorthm" class="section level4 hasAnchor" number="8.1.2.3">
<h4><span class="header-section-number">8.1.2.3</span> User-based Collaborative Filtering algorthm<a href="my-ds-summer-intern-preparation-guide.html#user-based-collaborative-filtering-algorthm" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<ul>
<li><p><strong><code>User based collaborative filtering algorithm</code></strong> finds similar users and gives them recommendations based on what other people with similar consumption patterns like to purchase as well.</p></li>
<li><p>While <strong><code>Item-based Collaborative Filtering</code></strong> finds similarity patterns between items themselves and recommends them to users based on the computed information.</p></li>
<li><p>In my internship for example, the goal of implementing this method was to decide what other courses we could recommend users to choose. Especially because our targeted customers are parents who have kids that are between 3-7 years old, and they usually purchase a general course bundles where they could decide later if they wanna let their kids learn courses within different categories such as sports, arts, and natural sciences, for example. In order to motivate them to consume or user those course credits within the bundle so that our business could actually make revenues or profits because our customers can always request a refund at anytime if they do not want to continue using these credits. In this case, the User-based Collaborative Filtering algorithm allows me to find parents whose kids might have similar interests or characteristics, and then we could recommend courses from other departments to our potential customers within the same customer segment based on the similarity of these customers.</p></li>
</ul>
</div>
<div id="rfm-analysis-and-k-means" class="section level4 hasAnchor" number="8.1.2.4">
<h4><span class="header-section-number">8.1.2.4</span> RFM analysis and k-means<a href="my-ds-summer-intern-preparation-guide.html#rfm-analysis-and-k-means" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<ul>
<li><p>RFM stands for <strong><code>Recency, Frequency, and Montary Analysis</code></strong>. It is an effective customer segmentation technique to help us make strategic choices in business, and in my internship example, it would be used to formulated targeted customer retention strategies based on different customer segments.</p></li>
<li><p>RFM essentially distinguishes and segments customers into similar clusters and targets them with separated and personalized promoting methodologies, which in turn makes strides in customer engagement and retention.</p></li>
<li><p>RFM metrics are very important to understand the behavior of customers as frequency and monetary value affects a customer’s lifetime value, and recency affects retention, which is a measure of engagement. I used a hybrid of RFM and K-Means clustering to investigate who are the best customers, who contribute to the churn rate etc. and cluster out customers into three main classes based on the level of priority our customer management team should focus on either maintaining this customer, or activating this customer if they had been relatively less responsive group.</p></li>
<li><p><strong><code>K-means</code></strong> is an iterative algorithm that tries to partition the dataset into K distinct clusters, in this case our primary customer information datasets which include when they start and quit using our services, how long and how often they use our services, etc.</p>
<ul>
<li><p>K-means tries to make the intra-cluster data points as similar as possible while also keeping the clusters as far as possible. It assigns data points to a cluster such that the sum of the squared distance between the data points and the cluster’s centroid is at the minimum.</p>
<ul>
<li><p>The fundamental step for any unsupervised algorithm is to determine the optimal number of clusters into which data may be clustered. I used two methods to decide K value for the K-means clustering. One is the Elbow method and another is silhouette score.</p>
<ul>
<li><p><strong><code>The Elbow Method i</code></strong>s a heuristic used in determining such optimal number of clusters. It is one of the most popular methods where we could simply plot the explained variation as a function of the number of clusters and picking the elbow of the curve as the number of clusters to use.</p></li>
<li><p><strong><code>The silhoutte analysis</code></strong> is an alternative. It is computed as the difference between the mean distance to the points in the nearest cluster that data point is not a part of and the mean intra-cluster distance to all the points in its own cluster, divided by the maximum value between these two.</p>
<ul>
<li>Silhoutte coeffcient is between-1 and 1, where 1 denotes the best meaning that data is very compact within cluster to which it belongs and far away from the other clusters.</li>
</ul></li>
<li><p>The major difference between elbow and silhoutte is that elbow only calculates the euclidean distance whereas silhoutte takes into account variables such as variance, skewness, high-low differences, etc.</p></li>
<li><p>Elbow is better for datasets with smaller size or time complexity because of its calculation simplicity.</p></li>
</ul></li>
</ul></li>
</ul></li>
</ul>
</div>
<div id="classification-predict-user-churn-rate" class="section level4 hasAnchor" number="8.1.2.5">
<h4><span class="header-section-number">8.1.2.5</span> classification –&gt; predict user churn rate<a href="my-ds-summer-intern-preparation-guide.html#classification-predict-user-churn-rate" class="anchor-section" aria-label="Anchor link to header"></a></h4>
</div>
</div>
<div id="intern3---data-science-intern" class="section level3 hasAnchor" number="8.1.3">
<h3><span class="header-section-number">8.1.3</span> Intern3 - Data Science Intern<a href="my-ds-summer-intern-preparation-guide.html#intern3---data-science-intern" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<div id="sql-pull-data-sql-templates" class="section level4 hasAnchor" number="8.1.3.1">
<h4><span class="header-section-number">8.1.3.1</span> SQL (pull data), SQL templates<a href="my-ds-summer-intern-preparation-guide.html#sql-pull-data-sql-templates" class="anchor-section" aria-label="Anchor link to header"></a></h4>
</div>
<div id="feature-engineering" class="section level4 hasAnchor" number="8.1.3.2">
<h4><span class="header-section-number">8.1.3.2</span> Feature Engineering<a href="my-ds-summer-intern-preparation-guide.html#feature-engineering" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>references: <a href="https://www.educative.io/blog/one-hot-encoding">Data Science in 5 minutes: What is One-hot Encoding?</a></p>
<p><a href="https://towardsdatascience.com/what-is-feature-engineering-importance-tools-and-techniques-for-machine-learning-2080b0269f10">What is feature engineering by Harshil Patel</a></p>
<p><a href="https://towardsdatascience.com/feature-engineering-for-machine-learning-3a5e293a5114#3abe">Fundamental Techniques of Feature Engineering for Machine Learning by Emre Rençberoğlu</a></p>
<ol style="list-style-type: decimal">
<li><p><strong><em>What is feature engineering?</em></strong></p>
<p>Feature engineering is the process of selecting, manipulating. and transforming raw data into desired features that can be used in statistical or machine learning approaches (e.g. supervised learning — predictive models).</p></li>
<li><p><strong><em>What is the goal of feature engineering?</em></strong></p>
<p>To simplify and speed up data transformations while also enhance model accuracy. becuz in raw data in real-life scenarios are often quite complex, we may have data type like texts, images, hyperlinks, etc. And regardless of the data or architecture, a terrible feature will have a direct impact on our model performance.</p></li>
<li><p><strong><em>What are the processes of feature engineering?</em></strong></p>
<ul>
<li><p><strong><code>Feature Creation:</code></strong> which creates features involving creating new variables which will be most helpful for our model. This can be adding, removing, or aggregating some features.</p></li>
<li><p><strong><code>Transformation:</code></strong> which is simply a function that transforms features from one representation to another without changing the actual values it meant to represent.</p></li>
<li><p><strong><code>Feature Extraction:</code></strong> the process of extracting features from a data set to identify useful information without distorting the original relationships or significant information. This process compresses the amount of data into manageable quantities for our algorithms to process.</p>
<ul>
<li><p><a href="https://www.analyticsvidhya.com/blog/2018/08/dimensionality-reduction-techniques-python/">12 Dimensionality Reduction Techniques with Python codes</a></p></li>
<li><p><a href="https://towardsdatascience.com/feature-extraction-using-principal-component-analysis-a-simplified-visual-demo-e5592ced100a#:~:text=PCA%20is%20a%20dimensionality%20reduction,understand%20the%20final%20two%20steps.">Feature Extraction using Principal Component Analysis by Kai Zhao</a></p></li>
<li><p><a href="https://towardsai.net/p/data-science/lda-vs-pca#:~:text=LDA%20focuses%20on%20finding%20a,variation%20in%20the%20data%20set.">LDA vs. PCA</a></p></li>
</ul></li>
<li><p><strong><code>Exploratory Data Analysis:</code></strong> EDA is a powerful and simple tool to improve our understanding of data by exploring its properties. The goal may be to create new hypotheses or find patterns in data.</p>
<ul>
<li>see some EDA techniques and sample code in python <a href="https://www.projectpro.io/article/exploratory-data-analysis-in-python-stop-drop-and-explore/427">here</a>.</li>
</ul></li>
<li><p><strong><code>Benchmark:</code></strong> a benchmark model is the most user-friendly, dependable, transparent, and interpretable model against which we can measure our own. It is a good idea to run test datasets to see if our new machine learning model outperforms a recognised benchmark. These benchmarks are often used as measures for comparing the performance between different machine learning models like neural networks and support vector machines, linear and non-linear classifiers, or different approaches like bagging and boosting.</p></li>
</ul></li>
<li><p><strong><em>What are the feature engineering techniques?</em></strong></p>
<ul>
<li><p><strong><code>Imputation:</code></strong> to deal with missing values coming from human errors, data flow interruptions, privacy concerns, or other factors contributing to missing values.</p>
<ul>
<li><p><strong><code>kNN Imputation:</code></strong> (k-nearest neighbor algorithm) —&gt; matching a point with its closet k neighbors in a multi-dimentional space.</p>
<ul>
<li><p>see kNN example in Python <a href="https://machinelearningmastery.com/knn-imputation-for-missing-values-in-machine-learning/">here</a>.</p></li>
<li><p><a href="https://towardsdatascience.com/the-use-of-knn-for-missing-values-cf33d935c637#:~:text=KNN%20is%20an%20algorithm%20that,all%20kind%20of%20missing%20data.">The use of KNN for missing values by Yohan Obadia</a></p></li>
</ul></li>
<li><p><strong><code>Drop entire rows or columns:</code></strong> we could use 70% as an example value and try to drop the rows and columns where missing values are higher than this threshold.</p>
<div class="sourceCode" id="cb32"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb32-1"><a href="my-ds-summer-intern-preparation-guide.html#cb32-1" aria-hidden="true" tabindex="-1"></a>threshold <span class="op">=</span> <span class="fl">0.7</span></span>
<span id="cb32-2"><a href="my-ds-summer-intern-preparation-guide.html#cb32-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb32-3"><a href="my-ds-summer-intern-preparation-guide.html#cb32-3" aria-hidden="true" tabindex="-1"></a><span class="co"># drop columns w/ missing value &gt; threshold</span></span>
<span id="cb32-4"><a href="my-ds-summer-intern-preparation-guide.html#cb32-4" aria-hidden="true" tabindex="-1"></a>data <span class="op">=</span> data[data.columns[data.isnull().mean() <span class="op">&lt;</span> threshold]]</span>
<span id="cb32-5"><a href="my-ds-summer-intern-preparation-guide.html#cb32-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb32-6"><a href="my-ds-summer-intern-preparation-guide.html#cb32-6" aria-hidden="true" tabindex="-1"></a><span class="co"># drop rows w/ missing value &gt; threshold</span></span>
<span id="cb32-7"><a href="my-ds-summer-intern-preparation-guide.html#cb32-7" aria-hidden="true" tabindex="-1"></a>data <span class="op">=</span> data.loc[data.isnull().mean(axis<span class="op">=</span><span class="dv">1</span>) <span class="op">&lt;</span> threshold]</span></code></pre></div></li>
<li><p><strong><code>Numerical Imputation:</code></strong> fill out missing values with 0 which represents NA. OR, to use the medians instead, becuz as the averages of columns are sensitive to outliers, while medians are more solid in this respect.</p>
<div class="sourceCode" id="cb33"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb33-1"><a href="my-ds-summer-intern-preparation-guide.html#cb33-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Filling all missing values with 0</span></span>
<span id="cb33-2"><a href="my-ds-summer-intern-preparation-guide.html#cb33-2" aria-hidden="true" tabindex="-1"></a>data <span class="op">=</span> data.fillna(<span class="dv">0</span>)</span>
<span id="cb33-3"><a href="my-ds-summer-intern-preparation-guide.html#cb33-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb33-4"><a href="my-ds-summer-intern-preparation-guide.html#cb33-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Filling missing values with medians of the columns</span></span>
<span id="cb33-5"><a href="my-ds-summer-intern-preparation-guide.html#cb33-5" aria-hidden="true" tabindex="-1"></a>data <span class="op">=</span> data.fillna(data.median())</span></code></pre></div></li>
<li><p><strong><code>Categorical Imputation:</code></strong> replace missing values with the highest value in the column. In some cases, if we believe values in this column are evenly distributed and there is NO dominating value, then imputing a category like “other” would be a better choice.</p>
<div class="sourceCode" id="cb34"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb34-1"><a href="my-ds-summer-intern-preparation-guide.html#cb34-1" aria-hidden="true" tabindex="-1"></a><span class="co">#Max fill function for categorical columns</span></span>
<span id="cb34-2"><a href="my-ds-summer-intern-preparation-guide.html#cb34-2" aria-hidden="true" tabindex="-1"></a>data[<span class="st">&#39;column_name&#39;</span>].fillna(data[<span class="st">&#39;column_name&#39;</span>].value_counts().idxmax(), inplace<span class="op">=</span><span class="va">True</span>)</span></code></pre></div></li>
</ul></li>
<li><p><strong><code>Handling Outliers:</code></strong> to remove outliers from dataset so that we can produce a more accurate data representation. Depending on the model, this effect of outliers could be large or minimal (e,g, linear regression is particularly susceptible to outliers so we need to handle them prior to model training)</p>
<ol style="list-style-type: decimal">
<li><p><strong><code>Removal:</code></strong> DELETE outiler completely from the distribution. However, if there are outliers across numerous variables, this strategy may result in a big chunk of data being missed,</p></li>
<li><p><strong><code>Replacing values:</code></strong> with suitable imputation</p></li>
<li><p><strong><code>Capping:</code></strong> use an arbitrary value or a value from a variable distribution to replace the maximum and minimum values.</p>
<div class="sourceCode" id="cb35"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb35-1"><a href="my-ds-summer-intern-preparation-guide.html#cb35-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Capping outlier rows with Percentiles</span></span>
<span id="cb35-2"><a href="my-ds-summer-intern-preparation-guide.html#cb35-2" aria-hidden="true" tabindex="-1"></a>upper_lim <span class="op">=</span> data[<span class="st">&#39;column&#39;</span>].quantile(<span class="fl">.95</span>)</span>
<span id="cb35-3"><a href="my-ds-summer-intern-preparation-guide.html#cb35-3" aria-hidden="true" tabindex="-1"></a>lower_lim <span class="op">=</span> data[<span class="st">&#39;column&#39;</span>].quantile(<span class="fl">.05</span>)</span>
<span id="cb35-4"><a href="my-ds-summer-intern-preparation-guide.html#cb35-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb35-5"><a href="my-ds-summer-intern-preparation-guide.html#cb35-5" aria-hidden="true" tabindex="-1"></a>data.loc[(df[column] <span class="op">&gt;</span> upper_lim), column] <span class="op">=</span> upper_lim</span>
<span id="cb35-6"><a href="my-ds-summer-intern-preparation-guide.html#cb35-6" aria-hidden="true" tabindex="-1"></a>data.loc[(df[column] <span class="op">&lt;</span> lower_lim), column] <span class="op">=</span> lower_lim</span></code></pre></div></li>
<li><p><strong><code>Discretization:</code></strong> convert continuous variable into discrete ones by constructing a series of continuous intervals (or bins) that span the range of our desired variable.</p>
<div class="sourceCode" id="cb36"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb36-1"><a href="my-ds-summer-intern-preparation-guide.html#cb36-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Numerical Binning Example</span></span>
<span id="cb36-2"><a href="my-ds-summer-intern-preparation-guide.html#cb36-2" aria-hidden="true" tabindex="-1"></a>VALUE      BIN</span>
<span id="cb36-3"><a href="my-ds-summer-intern-preparation-guide.html#cb36-3" aria-hidden="true" tabindex="-1"></a><span class="dv">0</span><span class="op">-</span><span class="dv">30</span>   <span class="op">-&gt;</span>  Low</span>
<span id="cb36-4"><a href="my-ds-summer-intern-preparation-guide.html#cb36-4" aria-hidden="true" tabindex="-1"></a><span class="dv">31</span><span class="op">-</span><span class="dv">70</span>  <span class="op">-&gt;</span>  Mid</span>
<span id="cb36-5"><a href="my-ds-summer-intern-preparation-guide.html#cb36-5" aria-hidden="true" tabindex="-1"></a><span class="dv">71</span><span class="op">-</span><span class="dv">100</span> <span class="op">-&gt;</span>  High</span>
<span id="cb36-6"><a href="my-ds-summer-intern-preparation-guide.html#cb36-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb36-7"><a href="my-ds-summer-intern-preparation-guide.html#cb36-7" aria-hidden="true" tabindex="-1"></a><span class="co"># Categorical Binning Example</span></span>
<span id="cb36-8"><a href="my-ds-summer-intern-preparation-guide.html#cb36-8" aria-hidden="true" tabindex="-1"></a>VALUE     BIN</span>
<span id="cb36-9"><a href="my-ds-summer-intern-preparation-guide.html#cb36-9" aria-hidden="true" tabindex="-1"></a>Spain  <span class="op">-&gt;</span> Europe</span>
<span id="cb36-10"><a href="my-ds-summer-intern-preparation-guide.html#cb36-10" aria-hidden="true" tabindex="-1"></a>Italy  <span class="op">-&gt;</span> Europe</span>
<span id="cb36-11"><a href="my-ds-summer-intern-preparation-guide.html#cb36-11" aria-hidden="true" tabindex="-1"></a>Brazil <span class="op">-&gt;</span> South America</span></code></pre></div></li>
</ol></li>
<li><p><strong><code>Log / BoxCox Transformation</code></strong></p>
<ul>
<li>to turn a skewed distribution into a normal or less-skewed distribution</li>
</ul></li>
<li><p><strong><code>One-hot Encoding:</code></strong> convert categorical variables such as gender, socio-economic status into a numerical form that can be processed by machine learning algorithms.</p>
<ul>
<li><p>In one-hot encoding, we could assign binary variable for categorical variables with two levels, and if it has more levels like race or weekdays, then we could convert these levels into ordered or non-ordered integers or numbers based on if there exists any order or relationship within these levels.</p>
<div class="sourceCode" id="cb37"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb37-1"><a href="my-ds-summer-intern-preparation-guide.html#cb37-1" aria-hidden="true" tabindex="-1"></a><span class="co"># one-hot encoding with pandas --&gt; create dummy variables</span></span>
<span id="cb37-2"><a href="my-ds-summer-intern-preparation-guide.html#cb37-2" aria-hidden="true" tabindex="-1"></a>pd.get_dummies(df.dataframe, prefix<span class="op">=</span><span class="st">&#39;column_name&#39;</span>)</span>
<span id="cb37-3"><a href="my-ds-summer-intern-preparation-guide.html#cb37-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb37-4"><a href="my-ds-summer-intern-preparation-guide.html#cb37-4" aria-hidden="true" tabindex="-1"></a><span class="co"># one-hot encoding with Sklearn</span></span>
<span id="cb37-5"><a href="my-ds-summer-intern-preparation-guide.html#cb37-5" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> sklearn.preprocessing <span class="im">as</span> preprocessing</span>
<span id="cb37-6"><a href="my-ds-summer-intern-preparation-guide.html#cb37-6" aria-hidden="true" tabindex="-1"></a>targets <span class="op">=</span> np.array[<span class="st">&#39;level1&#39;</span>,<span class="st">&#39;level2&#39;</span>,<span class="st">&#39;level3&#39;</span>]</span>
<span id="cb37-7"><a href="my-ds-summer-intern-preparation-guide.html#cb37-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb37-8"><a href="my-ds-summer-intern-preparation-guide.html#cb37-8" aria-hidden="true" tabindex="-1"></a>labelEnc <span class="op">=</span> preprocessing.LabelEncoder()</span>
<span id="cb37-9"><a href="my-ds-summer-intern-preparation-guide.html#cb37-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb37-10"><a href="my-ds-summer-intern-preparation-guide.html#cb37-10" aria-hidden="true" tabindex="-1"></a>new_target <span class="op">=</span> labelEnc.fit_transform(targets)</span>
<span id="cb37-11"><a href="my-ds-summer-intern-preparation-guide.html#cb37-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb37-12"><a href="my-ds-summer-intern-preparation-guide.html#cb37-12" aria-hidden="true" tabindex="-1"></a>onehotEnc <span class="op">=</span> preprocessing.OneHotEncoder()</span>
<span id="cb37-13"><a href="my-ds-summer-intern-preparation-guide.html#cb37-13" aria-hidden="true" tabindex="-1"></a>onhotEnc.fit(new_target.reshape(<span class="op">-</span><span class="dv">1</span>,<span class="dv">1</span>))</span>
<span id="cb37-14"><a href="my-ds-summer-intern-preparation-guide.html#cb37-14" aria-hidden="true" tabindex="-1"></a>targets_trans <span class="op">=</span> onehotEnc.transform(new_target.reshape(<span class="op">-</span><span class="dv">1</span>,<span class="dv">1</span>))</span></code></pre></div></li>
</ul></li>
<li><p><strong><code>Feature Splitting:</code></strong> improve value of features toward the target to be learned</p>
<ul>
<li><p><em>e.g. Data better contributes to the target function than Date and Time.</em></p>
<div class="sourceCode" id="cb38"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb38-1"><a href="my-ds-summer-intern-preparation-guide.html#cb38-1" aria-hidden="true" tabindex="-1"></a>df[<span class="st">&#39;Date and Time&#39;</span>] <span class="op">=</span> pd.to_datetime(df[<span class="st">&#39;Date and Time&#39;</span>])</span>
<span id="cb38-2"><a href="my-ds-summer-intern-preparation-guide.html#cb38-2" aria-hidden="true" tabindex="-1"></a>df[<span class="st">&#39;Date&#39;</span>] <span class="op">=</span> df[<span class="st">&#39;Date and Time&#39;</span>].dt.date</span></code></pre></div></li>
</ul></li>
<li><p><strong><code>Scaling:</code></strong> the scaling operation makes continuous features become similar in terms of range so that we could effectively save the model training time.</p>
<ol style="list-style-type: decimal">
<li><p><strong><code>Normalization:</code></strong> where all values are scaled in a specified range between 0 and 1 via min-max normalization. This modification has no influence on the feature’s distribution but it does exacerbate the effects of outliers due to lower standard deviations.</p>
<span class="math display">\[\begin{equation}
\frac{\text{x - min(x)}}{\text{max(x) - min(x)}}
\end{equation}\]</span>
<div class="sourceCode" id="cb39"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb39-1"><a href="my-ds-summer-intern-preparation-guide.html#cb39-1" aria-hidden="true" tabindex="-1"></a>data[<span class="st">&#39;normalized&#39;</span>] <span class="op">=</span> (data[<span class="st">&#39;value&#39;</span>] <span class="op">-</span> data[<span class="st">&#39;value&#39;</span>].<span class="bu">min</span>()) <span class="op">/</span> (data[<span class="st">&#39;value&#39;</span>].<span class="bu">max</span>() <span class="op">-</span> data[<span class="st">&#39;value&#39;</span>].<span class="bu">max</span>() <span class="op">-</span> data[<span class="st">&#39;value&#39;</span>].<span class="bu">min</span>())</span></code></pre></div></li>
<li><p><strong><code>Standardization:</code></strong> (also known as z-score normalization) is the process of scaling values while accounting for standard deviation. To arrive at a distribution with a 0 mean and 1 variance, all data points are subtracted by their mean and the result divided by the distribution’s variance. If the standard deviation of features differs, the range of those features will likewise differ.</p>
<span class="math display">\[\begin{equation}
\frac{X - \mu}{\sigma}
\end{equation}\]</span>
<div class="sourceCode" id="cb40"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb40-1"><a href="my-ds-summer-intern-preparation-guide.html#cb40-1" aria-hidden="true" tabindex="-1"></a>data[<span class="st">&#39;standardized&#39;</span>] <span class="op">=</span> (data[<span class="st">&#39;value&#39;</span>] <span class="op">-</span> data[<span class="st">&#39;value&#39;</span>].mean()) <span class="op">/</span> data[<span class="st">&#39;value&#39;</span>].std()</span></code></pre></div></li>
</ol></li>
</ul></li>
<li><p><strong><em>How do you evaluate model performances?</em></strong></p></li>
<li><p><strong><em>Explain k-fold cross validation.</em></strong></p></li>
<li><p><strong><em>Cross Validation in Time Series?</em></strong></p></li>
<li><p><strong><em>What is the difference between supervised and unsupervised learning?</em></strong></p></li>
<li><p><strong><em>What is feature?</em></strong></p>
<p>A feature is any measurable input (variable of interests) that can be used in a predictive model. For example, in our consumer coupon prediction model, we may be interested in taking demographic, geographical, or environmental features into account such as the level of consumers income, the region or city they come from, and holidays etc.</p></li>
</ol>
</div>
</div>
<div id="capstone-research" class="section level3 hasAnchor" number="8.1.4">
<h3><span class="header-section-number">8.1.4</span> Capstone research<a href="my-ds-summer-intern-preparation-guide.html#capstone-research" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>reference: <a href="https://www.investopedia.com/terms/a/autoregressive-integrated-moving-average-arima.asp">ARIMA by Adam Hayes</a> | <a href="https://www.infoworld.com/article/3622246/an-introduction-to-time-series-forecasting.html">An Introduction to Time Series Forecast</a> | <a href="https://lost-stats.github.io/Time_Series/GARCH_Model.html">GARCH</a></p>
<div id="time-series-forecasting-exponential-smooth-arima-garch--differences-pros-and-cons" class="section level4 hasAnchor" number="8.1.4.1">
<h4><span class="header-section-number">8.1.4.1</span> time series forecasting (exponential smooth / ARIMA / GARCH)- differences, pros and cons<a href="my-ds-summer-intern-preparation-guide.html#time-series-forecasting-exponential-smooth-arima-garch--differences-pros-and-cons" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<ol style="list-style-type: decimal">
<li><p><strong><em>What is time series forecasting?</em></strong></p>
<p>To forecast or predict the future value or event over a period of time. It predicts future events by analyzing the trends of the past based on historical records. Time series forecasting is also an important area of machine learning and can be cast as a supervised learning problem.</p></li>
<li><p><strong><em>What is ARIMA?</em></strong></p>
<p>ARIMA is called the autoregressive integrated moving average, It is a method for forecasting or predicting future outcomes based on historical time series. It is based on the statistical concept of serial correlation, where past data points influence future data points. <em>(The ARIMA model can also be understood as a form of regression analysis that gauges the strength of one dependent variable relative to other changing variables. Its goal is to predict future values by examining the differences between values in the series instead of through actual values.)</em></p>
<p>An ARIMA model can also be understood by each of the three components. The first one is autoregression, the AR part of the model that shows a changing variable that regresses on its own lagged or prior values. 2) The Integrated (I) part of the model represents the differencing of raw observations to allow for time series to become stationary (i.e. in this process, data values are replaced by the difference between data values and previous values). 3) The last part, moving average, the MA part of the model incorporates the dependency between an observation and a residual error from a moving average model applied to lagged observations.</p></li>
<li><p><strong><em>What is SARIMA?</em></strong></p>
<p>For this research, I adjusted the algorithm to either select an ARIMA or a SARIMA model based on if there exists any seasonal considerations we need to account for. The SARIMA, which is a seasonal ARIMA model, extends ARIMA by adding a linear combination of seasonal past values and/or forecast errors.</p></li>
<li><p><strong><em>What are the differences between Autoregressive and Moving Average models?</em></strong></p>
<p>So an autoregressive model with a lag order of 1, for example, is a process where current value is based on its immediately preceding value like yesterday, while in an AR model with a lag order of 2, the current value is based on the previous two values like both yesterday and the day before yesterday.</p>
<p>A moving average, though, is a calculation used to analyze data points by creating a series of averages of different subsets from the full data set in order to smooth out the influence of outliers.</p>
<p>ARIMA combines autoregressive features with those of moving averages so that it can take into account trends, cycles, seasonality, and other non-static types of data when making forecasts.</p></li>
<li><p><strong><em>What is GARCH?</em></strong></p>
<p>GARCH stands for generalized autoregressive conditional heteroskedasticity, and it is a statistical model used to analyze some particular time series data when the variance error is believed to be serially autocorrelated. GARCH models assume that the variance of the error term also follows an autoregressive moving average process. In order words, we usually implement GARCH on the fitted ARIMA model. GARCH can be very useful to help predict the volatility of returns on financial assets. Volatility can be understood as how much and how quickly the value moves over a given span of time, for example, we can use price volatility to describe price fluctuations of a commodity.</p></li>
<li><p><strong><em>What are other time series forecasting techniques?</em></strong></p>
<p>There are many other useful statistical and machine learning models for time series analysis. For example, regression models, exponential smoothing methods (which produce forecasts based on weighted averages of past observations, in other words, exponential smoothing produces forecasts where the forecast most closely resembles recent observations). Some useful popular exponential smoothing methods include the DES (double exponential smoothing) whose forecasts are weighted averages of both the trend and time series itself, as well as the Holt-Winter method which accounts for both trend and seasonality.</p>
<p>Machine learning techniques like neural networks are also quite popular in time series analysis because they aim to solve problems that would be impossible or difficult to solve with these statistical or classical methods. For example, the recurrent neural networks (RNNs) were deigned to try remember important information about recent inputs so that they can be used to generate accurate forecasts. The LSTM (long short-term memory) network is a particular useful type of RNN in time series analysis. It basically has some forget gates and feed forward mechanisms that allow the network to retain information, forget non-important or not relevant inputs, and update the forecasting procedure to model and forecast more complex time series problems.</p></li>
<li><p><strong><em>What is the difference between exponential smoothing and ARIMA?</em></strong></p>
<p>While exponential smoothing methods generates forecasts based on historical components of the data, ARIMA models take advantages of autocorrelation to produce forecasts. (Autocorrelation is when a time series displays correlation between time series and a lagged version of the time series, which simply means that current values also depend on previous values.)</p></li>
</ol>
</div>
<div id="time-series-clustering-dynamic-time-warping-hierarchical-clustering" class="section level4 hasAnchor" number="8.1.4.2">
<h4><span class="header-section-number">8.1.4.2</span> time series clustering –&gt; Dynamic Time Warping, hierarchical clustering<a href="my-ds-summer-intern-preparation-guide.html#time-series-clustering-dynamic-time-warping-hierarchical-clustering" class="anchor-section" aria-label="Anchor link to header"></a></h4>
</div>
<div id="k-medoids-clustering-mixed-data-type" class="section level4 hasAnchor" number="8.1.4.3">
<h4><span class="header-section-number">8.1.4.3</span> k-medoids clustering (mixed data type)<a href="my-ds-summer-intern-preparation-guide.html#k-medoids-clustering-mixed-data-type" class="anchor-section" aria-label="Anchor link to header"></a></h4>
</div>
<div id="test-for-stationarity-augmented-dickey-fuller-test-normality-shapiro-wilk-conditinal-heteroscedasticity-arch-lm-box-cox-transformation" class="section level4 hasAnchor" number="8.1.4.4">
<h4><span class="header-section-number">8.1.4.4</span> test for stationarity (Augmented Dickey-Fuller test), normality (Shapiro Wilk), conditinal heteroscedasticity (ARCH LM), Box-Cox transformation<a href="my-ds-summer-intern-preparation-guide.html#test-for-stationarity-augmented-dickey-fuller-test-normality-shapiro-wilk-conditinal-heteroscedasticity-arch-lm-box-cox-transformation" class="anchor-section" aria-label="Anchor link to header"></a></h4>
</div>
</div>
</div>
<div id="sql-python-r-tableau" class="section level2 hasAnchor" number="8.2">
<h2><span class="header-section-number">8.2</span> SQL | Python | R | Tableau<a href="my-ds-summer-intern-preparation-guide.html#sql-python-r-tableau" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<div id="basic-statistics" class="section level3 hasAnchor" number="8.2.1">
<h3><span class="header-section-number">8.2.1</span> Basic Statistics:<a href="my-ds-summer-intern-preparation-guide.html#basic-statistics" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<ul>
<li><p>Confidence intervals</p></li>
<li><p>Tests of Hypotheses</p></li>
<li><p>T-tests, correlation, regression, analysis of variance, chi-square tests</p></li>
</ul>
</div>
</div>
<div id="probability-usually-test-easy-medium-prob-questions" class="section level2 hasAnchor" number="8.3">
<h2><span class="header-section-number">8.3</span> Probability: (usually test easy-medium prob questions)<a href="my-ds-summer-intern-preparation-guide.html#probability-usually-test-easy-medium-prob-questions" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<ul>
<li><p><code>Probability spaces</code> as models for phenomena with statistical regularity</p></li>
<li><p><code>Discrete spaces (binomial, hypergeometric, Poisson)</code></p></li>
<li><p><code>Continuos spaces (normal, exponential) and densities</code></p></li>
<li><p>Random Variables | Expectation | Independence</p></li>
<li><p>Conditional probability</p></li>
<li><p>The Laws of large numbers</p></li>
<li><p>Central Limit Theorem (CLT)</p></li>
</ul>
<p><strong><em><code>MOST ASKED MATH TOPICS:</code></em></strong></p>
<ul>
<li><p>PROB:</p>
<ul>
<li><p>probability theorems</p></li>
<li><p>sampling &amp; experimental design</p></li>
<li><p>random variables, PDF/CDF, expected values, etc.</p></li>
</ul></li>
<li><p>STATS</p>
<ul>
<li><p>book: <code>Practical statistics for data scientists (Bruce)</code> | engineering statistics handbook (NIST) | Statistical inference (Casella &amp; Berger)</p></li>
<li><p>A/B Testing, hypothesis test</p></li>
<li><p>differences of every type of distribution and how to test such type</p></li>
<li><p>OLS and logistic</p></li>
</ul></li>
</ul>
</div>
<div id="ml-theory-for-ds-modeling-job" class="section level2 hasAnchor" number="8.4">
<h2><span class="header-section-number">8.4</span> ML Theory (for DS-Modeling job)<a href="my-ds-summer-intern-preparation-guide.html#ml-theory-for-ds-modeling-job" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<ul>
<li>book: Introduction to Statistical Learning | Elements of statistical learning | Hands-on ML with Scikit Learn, Keras, and TensorFlow (by OREILLY)</li>
<li>bias variance | sampling | under/overfitting | feature engineering | model evaluation</li>
<li>how to select an apropriate model and features</li>
<li>pros and cons of different models</li>
<li>ETL pipeline/model, prod readiness</li>
</ul>
</div>
<div id="ab-testing-and-product-sense" class="section level2 hasAnchor" number="8.5">
<h2><span class="header-section-number">8.5</span> A/B Testing and Product Sense<a href="my-ds-summer-intern-preparation-guide.html#ab-testing-and-product-sense" class="anchor-section" aria-label="Anchor link to header"></a></h2>
</div>
<div id="statistical-testing" class="section level2 hasAnchor" number="8.6">
<h2><span class="header-section-number">8.6</span> Statistical Testing<a href="my-ds-summer-intern-preparation-guide.html#statistical-testing" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<ul>
<li><p>parametric vs. non-parametric</p>
<ul>
<li><p>each method’s assumptions and pros &amp; cons</p></li>
<li><p>differences: parametric –&gt; independent, unbiased sample | non-parametric –&gt; ?</p></li>
</ul></li>
<li><p><code>case studies -- experiment design:</code></p>
<ul>
<li><p>mean, standard deviation, median, IQR</p></li>
<li><p>Hypothesis testing</p>
<ul>
<li><p>h0 / h1</p></li>
<li><p>choose statistical test and significance level</p></li>
<li><p>test statistics</p></li>
</ul></li>
<li><p>correlation (pearson / Spearman rank / Kendall rank)</p></li>
<li><p>one-sample / two sample t-test | ANOVA | chi-square –&gt; goodness of fit, contigency</p></li>
<li><p>test distribution</p>
<ul>
<li><p>histogram, skewness, kurtosis</p></li>
<li><p>KS (Kolmogorov-Smirnov) test</p></li>
<li><p>Shapiro-Wilk</p></li>
<li><p>68-95-99.7</p></li>
</ul></li>
</ul></li>
</ul>
</div>
<div id="behavioral-questions" class="section level2 hasAnchor" number="8.7">
<h2><span class="header-section-number">8.7</span> Behavioral Questions<a href="my-ds-summer-intern-preparation-guide.html#behavioral-questions" class="anchor-section" aria-label="Anchor link to header"></a></h2>

</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="product-sense.html" class="navigation navigation-prev navigation-unique" aria-label="Previous page"><i class="fa fa-angle-left"></i></a>

    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"whatsapp": false,
"all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": "https://github.com/cyanjiner/ds-job-prep-notes/edit/master/07-my-intern-prep.Rmd",
"text": "Edit"
},
"history": {
"link": null,
"text": null
},
"view": {
"link": "https://github.com/cyanjiner/ds-job-prep-notes/blob/master/07-my-intern-prep.Rmd",
"text": null
},
"download": null,
"search": {
"engine": "fuse",
"options": null
},
"toc": {
"collapse": "subsection"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.9/latest.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
